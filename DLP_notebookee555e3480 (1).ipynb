{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":95302,"databundleVersionId":11325230,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:18:15.358908Z","iopub.execute_input":"2025-03-09T13:18:15.359261Z","iopub.status.idle":"2025-03-09T13:18:15.369405Z","shell.execute_reply.started":"2025-03-09T13:18:15.359233Z","shell.execute_reply":"2025-03-09T13:18:15.368501Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/indic-tts-deepfake-challenge/sample.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Official dataset for this challenge\ndataset = load_dataset(\"SherryT997/IndicTTS-Deepfake-Challenge-Data\")  \n\n# Train and test splits\ntrain_data = dataset[\"train\"]  # Contains 'is_tts' labels\ntest_data = dataset[\"test\"]  # 'is_tts' is -1 for all rows\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:18:16.122923Z","iopub.execute_input":"2025-03-09T13:18:16.123268Z","iopub.status.idle":"2025-03-09T13:24:45.060639Z","shell.execute_reply.started":"2025-03-09T13:18:16.123238Z","shell.execute_reply":"2025-03-09T13:24:45.059712Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"844cbc4c5d624516acf2fc97ee2ce34d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5860ce23cd9b499a8b4d420bcab547ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b838a8bb76c346d1b44f82fed273ba40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/35 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd6ab3e11949412caf1188b38b6ca929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00035.parquet:   0%|          | 0.00/453M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b073489cd6ad498797595b8343cc21e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00035.parquet:   0%|          | 0.00/461M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b740c3c2e2f406cadfd17c6eefbf436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00035.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5449748ae16546bdb1ab35950c40052a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00035.parquet:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c41b3fcf077244d788ef11218db64c82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00035.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"687cc116f3e64d63939c3811dd0f040d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00035.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f592c8bbb3c5428697ee86a5c8ea793c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00035.parquet:   0%|          | 0.00/447M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdfa0a1644474792b2c2dcd86395d0b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00035.parquet:   0%|          | 0.00/516M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2daf2f2061f4ae587ade8ea97321bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00035.parquet:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0957100019c94545abd1db38cfda09f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00035.parquet:   0%|          | 0.00/521M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"005b19e5924a408a8d410c89a7575ae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00035.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61fdf89515384e53be7e8ee543b4954e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00035.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d9f61560894adea989c70a386312f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00035.parquet:   0%|          | 0.00/414M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5f7f6f6e1940e7aab8b3c7f67c501a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00035.parquet:   0%|          | 0.00/473M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbfc0fd349d44256b379c82ca161167c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00035.parquet:   0%|          | 0.00/481M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79ea5af606204396a93c26641e35b6fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00035.parquet:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a219863d7f84eaa857b19a5a4c88f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00035.parquet:   0%|          | 0.00/532M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c64ed7919ad74f2a8dbb4dba00f7d309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00035.parquet:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72334c8fa4bb4d4c9e24f8e9a84f72f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00035.parquet:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d9bf0457677451aa8ea5fb392526a62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00035.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bed9528eb92e42e1b808c8453415c642"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00035.parquet:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9203b00dc8b34ea4a4bc1f4072ac1671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00035.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a56daacd26c448fbfed3afefb9ee049"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00035.parquet:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5540bbddec514ef285443568ba4abef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00035.parquet:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ac087c34f7f447792afccd5dc9f4b00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00035.parquet:   0%|          | 0.00/576M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e253052d454ebb86cbbe89b7c330dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00035.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0a1c8f32fc4efeb44d2a68b589d15a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00035.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534b150e6e304525b6fefc2d66900440"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00035.parquet:   0%|          | 0.00/421M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42aafe9ecf5a448a953563a6ce3e27ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00035.parquet:   0%|          | 0.00/382M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cddf799838249c69c767d3573a25754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00035.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7397ff52d2824f9491ce046e5b594a72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00030-of-00035.parquet:   0%|          | 0.00/282M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e102365d271a412baa175010e580c96c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00031-of-00035.parquet:   0%|          | 0.00/688M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"911ec00f74f4456781a20ce68a8993d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00032-of-00035.parquet:   0%|          | 0.00/613M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b440799c7b7d400aa8e09b873db1c1a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00033-of-00035.parquet:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76415d42aa4f42069f91b6ad73ceb948"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00034-of-00035.parquet:   0%|          | 0.00/424M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6ccdd31228049aabdd14f8cc818dd65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00004.parquet:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182f00b62c294520911473de0e49c500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00001-of-00004.parquet:   0%|          | 0.00/364M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66a3d93efe44d83965da508605ff79f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00002-of-00004.parquet:   0%|          | 0.00/410M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56f979a52ad44cb8a01f27e9aa9b84e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00003-of-00004.parquet:   0%|          | 0.00/291M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b70ba6818404b78a426797e73b23a9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/31102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a883ddfe64bc471baa444fb8caacc1b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14a4b87543914f1991bb504eacf4d5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24571904e5594cbe91f698773c0cdfa1"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train=train_data.shuffle()\n# train=train.shuffle()\n\nsubset=train.select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:45.061968Z","iopub.execute_input":"2025-03-09T13:24:45.062317Z","iopub.status.idle":"2025-03-09T13:24:45.108340Z","shell.execute_reply.started":"2025-03-09T13:24:45.062284Z","shell.execute_reply":"2025-03-09T13:24:45.107521Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# subset[:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:45.112272Z","iopub.execute_input":"2025-03-09T13:24:45.112597Z","iopub.status.idle":"2025-03-09T13:24:50.055251Z","shell.execute_reply.started":"2025-03-09T13:24:45.112565Z","shell.execute_reply":"2025-03-09T13:24:50.054242Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!pip install datasets transformers torchaudio librosa > /dev/null\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:50.057145Z","iopub.execute_input":"2025-03-09T13:24:50.057490Z","iopub.status.idle":"2025-03-09T13:24:55.911833Z","shell.execute_reply.started":"2025-03-09T13:24:50.057466Z","shell.execute_reply":"2025-03-09T13:24:55.910731Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torchaudio\nfrom transformers import Wav2Vec2Processor, Wav2Vec2Model\nimport os\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:55.913013Z","iopub.execute_input":"2025-03-09T13:24:55.913352Z","iopub.status.idle":"2025-03-09T13:24:56.818569Z","shell.execute_reply.started":"2025-03-09T13:24:55.913320Z","shell.execute_reply":"2025-03-09T13:24:56.817691Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Extracting Embeddings:","metadata":{}},{"cell_type":"code","source":"# subset['audio'][:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:56.819510Z","iopub.execute_input":"2025-03-09T13:24:56.819733Z","iopub.status.idle":"2025-03-09T13:24:56.822943Z","shell.execute_reply.started":"2025-03-09T13:24:56.819716Z","shell.execute_reply":"2025-03-09T13:24:56.822328Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Extract audio arrays from subset\naudio_arrays = [item['array'] for item in subset['audio']]\n\n# Add the 'audio_array' column directly\ndataset_train = subset.add_column('audio_array', audio_arrays)\n\n# # Verify the new column\n# print(dataset_train[0]['audio_array'][:10])\n# print(dataset_train.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:56.823647Z","iopub.execute_input":"2025-03-09T13:24:56.823845Z","iopub.status.idle":"2025-03-09T13:25:24.783131Z","shell.execute_reply.started":"2025-03-09T13:24:56.823829Z","shell.execute_reply":"2025-03-09T13:25:24.782230Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39eecd9359a041948c6e56eed241d04e"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Extract audio arrays from subset\naudio_arrays = [item['array'] for item in test_data['audio']]\n\n# Add the 'audio_array' column directly\ndataset_test = test_data.add_column('audio_array', audio_arrays)\n\n# # Verify the new column\n# print(dataset_train[0]['audio_array'][:10])\n# print(dataset_train.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:25:24.785387Z","iopub.execute_input":"2025-03-09T13:25:24.785920Z","iopub.status.idle":"2025-03-09T13:25:51.325415Z","shell.execute_reply.started":"2025-03-09T13:25:24.785896Z","shell.execute_reply":"2025-03-09T13:25:51.324705Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset_train,dataset_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:25:51.326399Z","iopub.execute_input":"2025-03-09T13:25:51.326697Z","iopub.status.idle":"2025-03-09T13:25:51.331818Z","shell.execute_reply.started":"2025-03-09T13:25:51.326668Z","shell.execute_reply":"2025-03-09T13:25:51.331028Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_array'],\n     num_rows: 1000\n }),\n Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_array'],\n     num_rows: 2635\n }))"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom transformers import Wav2Vec2Processor, Wav2Vec2Model\nfrom datasets import Dataset  # Assuming dataset is a Hugging Face Dataset\n\n# Load the Wav2Vec 2.0 model and processor\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\nmodel = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\n# Function to extract embeddings from audio data\ndef extract_embeddings(example):\n    audio_array = example['audio']['array']  # Extract audio array\n    sample_rate = example['audio']['sampling_rate']\n\n    # Resample if the sampling rate is not 16kHz\n    if sample_rate != 16000:\n        audio_array = torchaudio.transforms.Resample(sample_rate, 16000)(torch.tensor(audio_array))\n\n    # Process the waveform for the model\n    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n\n    # Extract embeddings\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Extract the last hidden state as embeddings (or pool if needed)\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n\n    # Add embeddings to the dataset\n    example['audio_embeddings'] = embeddings\n    return example\n\n\n# Map the embedding extraction function\ndataset_train = subset.map(extract_embeddings)\n\n# Check output\n# print(dataset[0]['audio_embeddings'].shape)  # Expected output: (768,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:26:45.109583Z","iopub.execute_input":"2025-03-09T13:26:45.109916Z","iopub.status.idle":"2025-03-09T13:38:09.045235Z","shell.execute_reply.started":"2025-03-09T13:26:45.109890Z","shell.execute_reply":"2025-03-09T13:38:09.044254Z"}},"outputs":[{"name":"stderr","text":"Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ad51bc31eca4f9b929f4804057e4756"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# dataset_train['audio_embeddings'][:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:42:14.517469Z","iopub.execute_input":"2025-03-09T02:42:14.517843Z","iopub.status.idle":"2025-03-09T02:42:14.969300Z","shell.execute_reply.started":"2025-03-09T02:42:14.517815Z","shell.execute_reply":"2025-03-09T02:42:14.968243Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[[-0.044041793793439865,\n  0.012884334661066532,\n  -0.015163351781666279,\n  -0.02633092738687992,\n  0.0851236879825592,\n  -0.06182975322008133,\n  0.061708856374025345,\n  -0.03552279993891716,\n  0.026822388172149658,\n  -0.2951536476612091,\n  -0.043685927987098694,\n  -0.01577705703675747,\n  0.03703310340642929,\n  0.040204375982284546,\n  -0.18982668220996857,\n  0.01588919386267662,\n  -0.28721973299980164,\n  0.34316495060920715,\n  0.01779666170477867,\n  0.06850619614124298,\n  -0.19890627264976501,\n  0.07195549458265305,\n  0.06802411377429962,\n  0.018082400783896446,\n  0.21441401541233063,\n  -0.014859815128147602,\n  -0.262512743473053,\n  -0.005623433273285627,\n  -0.007746524177491665,\n  -0.10318316519260406,\n  0.13156624138355255,\n  -0.01049379725009203,\n  -0.11909525096416473,\n  -0.06912849843502045,\n  -0.1711677461862564,\n  -0.07443375140428543,\n  -0.02493377961218357,\n  -0.2574174404144287,\n  -0.10336143523454666,\n  -0.026921767741441727,\n  -0.165060356259346,\n  0.002119589364156127,\n  -0.15748248994350433,\n  0.153670996427536,\n  -0.13205385208129883,\n  0.192123681306839,\n  -0.04110676050186157,\n  -0.026866616681218147,\n  0.04058869928121567,\n  0.027587687596678734,\n  -0.1101607158780098,\n  -0.03298523649573326,\n  0.030093228444457054,\n  0.02677995339035988,\n  0.0044660428538918495,\n  0.002453682478517294,\n  0.011650261469185352,\n  -0.4320557713508606,\n  -0.15764766931533813,\n  -0.14131306111812592,\n  -0.02293204888701439,\n  -0.11316143721342087,\n  0.020401859655976295,\n  0.1620924472808838,\n  -0.025387512519955635,\n  0.10453552007675171,\n  -0.009647410362958908,\n  -0.12301529198884964,\n  -0.14460839331150055,\n  -0.03087998740375042,\n  -0.09429889172315598,\n  -0.030897153541445732,\n  -0.08553845435380936,\n  -0.06394124031066895,\n  0.035942476242780685,\n  0.029090246185660362,\n  0.04716035723686218,\n  0.04511285200715065,\n  -0.02340579777956009,\n  -0.0666920393705368,\n  -0.09464721381664276,\n  0.2835168242454529,\n  0.037605296820402145,\n  0.062177207320928574,\n  -0.024505360051989555,\n  0.07651372998952866,\n  -0.08199843764305115,\n  -0.18021634221076965,\n  -0.015766562893986702,\n  0.029357248917222023,\n  0.22141602635383606,\n  -0.0962432399392128,\n  0.10173820704221725,\n  0.02429940551519394,\n  0.04149588197469711,\n  -0.02820834144949913,\n  0.07589277625083923,\n  0.03909013047814369,\n  -0.031843800097703934,\n  -0.07941491156816483,\n  -0.010627920739352703,\n  -0.16917282342910767,\n  0.005199537146836519,\n  -0.18471543490886688,\n  0.1313999742269516,\n  0.2690185606479645,\n  -0.0297684445977211,\n  0.15655744075775146,\n  0.01347431167960167,\n  0.07609381526708603,\n  -0.024715261533856392,\n  -0.03678971529006958,\n  -0.06554921716451645,\n  0.013516760431230068,\n  -0.0884627178311348,\n  0.003340846160426736,\n  0.04752131924033165,\n  -0.025982212275266647,\n  -0.04584300145506859,\n  -0.15691804885864258,\n  0.057090044021606445,\n  0.003888025414198637,\n  0.0936034694314003,\n  0.006759887561202049,\n  -0.04816238209605217,\n  -0.19947880506515503,\n  0.05621647834777832,\n  0.31245288252830505,\n  -0.08957429230213165,\n  0.11062272638082504,\n  -0.003949716687202454,\n  -0.06695147603750229,\n  -0.08781491965055466,\n  -0.01928335800766945,\n  -0.07157924771308899,\n  -0.03341851010918617,\n  -0.08239129185676575,\n  -0.008810740895569324,\n  -0.015476389788091183,\n  -0.4297753870487213,\n  0.007527146954089403,\n  0.0690392479300499,\n  -0.015437697060406208,\n  0.3110445439815521,\n  0.022849198430776596,\n  0.003335535293444991,\n  -0.6207767724990845,\n  0.10515519231557846,\n  -0.23178748786449432,\n  0.08127692341804504,\n  0.01049890648573637,\n  0.14218252897262573,\n  0.09668982774019241,\n  -0.1173713356256485,\n  0.05099155381321907,\n  0.005074435845017433,\n  -0.0037695413921028376,\n  -0.005130311939865351,\n  0.274164617061615,\n  -0.07085681706666946,\n  -0.13829059898853302,\n  0.22967860102653503,\n  0.14380168914794922,\n  -0.010458881966769695,\n  0.039197828620672226,\n  -0.03635686635971069,\n  -0.05553833022713661,\n  -0.12493353337049484,\n  0.33943381905555725,\n  0.14837172627449036,\n  0.04055624455213547,\n  -0.09378678351640701,\n  0.048813022673130035,\n  0.24112877249717712,\n  -0.005223051644861698,\n  -0.2013818919658661,\n  -0.06641434133052826,\n  0.024216139689087868,\n  -0.0527561753988266,\n  0.00753498449921608,\n  -0.02414369396865368,\n  -0.010311124846339226,\n  -0.0018921408336609602,\n  -0.23609228432178497,\n  -0.10896699875593185,\n  -0.03584987297654152,\n  -0.04922915995121002,\n  -0.312338262796402,\n  -0.10077332705259323,\n  0.13558442890644073,\n  -0.07066494971513748,\n  -0.039921488612890244,\n  -0.06397747248411179,\n  -0.01069930661469698,\n  -0.03212335705757141,\n  0.08598480373620987,\n  -0.13654853403568268,\n  0.24497762322425842,\n  -0.08465080708265305,\n  -0.058637671172618866,\n  0.020867619663476944,\n  0.015047895722091198,\n  -0.2779436409473419,\n  0.14675569534301758,\n  -0.13283410668373108,\n  0.1393977850675583,\n  0.009648695588111877,\n  -0.0516679584980011,\n  0.06604369729757309,\n  0.24507369101047516,\n  -0.4780069887638092,\n  0.07542775571346283,\n  -0.006510363891720772,\n  0.014925936236977577,\n  0.029506342485547066,\n  -0.08576350659132004,\n  0.05071618780493736,\n  -0.15788961946964264,\n  -0.028137758374214172,\n  0.05584230273962021,\n  -0.10246957838535309,\n  -0.031423501670360565,\n  -0.19093602895736694,\n  0.005979034584015608,\n  -0.08937046676874161,\n  0.08488410711288452,\n  -0.005422081332653761,\n  0.22019915282726288,\n  -0.10284659266471863,\n  0.07471976429224014,\n  0.14998792111873627,\n  -0.03576669096946716,\n  0.041076093912124634,\n  -0.004727677442133427,\n  -0.011531167663633823,\n  -0.010473729111254215,\n  -0.003062075935304165,\n  -0.002368490444496274,\n  -0.023715991526842117,\n  0.05777382850646973,\n  0.04938695207238197,\n  -0.2759154736995697,\n  0.007597635965794325,\n  -0.05651974305510521,\n  -0.17297028005123138,\n  0.020427417010068893,\n  -0.03527655825018883,\n  0.15787114202976227,\n  0.07565953582525253,\n  -0.13832974433898926,\n  -0.031047377735376358,\n  0.17043046653270721,\n  -0.020465882495045662,\n  0.026342658326029778,\n  -0.0042574782855808735,\n  0.08917500823736191,\n  -0.32322072982788086,\n  0.03914991021156311,\n  0.049015939235687256,\n  -0.10729210823774338,\n  0.03889874741435051,\n  0.03862447291612625,\n  -0.03082260675728321,\n  0.007333050947636366,\n  -0.3011787533760071,\n  0.10447440296411514,\n  -0.031488463282585144,\n  -0.06383942812681198,\n  -0.03873497620224953,\n  -0.3234107792377472,\n  0.00912072416394949,\n  0.18775340914726257,\n  -0.0239675585180521,\n  0.01611490361392498,\n  -0.07632095366716385,\n  -0.048200398683547974,\n  0.006911206524819136,\n  0.018116673454642296,\n  -0.07414975017309189,\n  0.24413961172103882,\n  -0.06900918483734131,\n  0.08615517616271973,\n  0.09347642958164215,\n  0.12321927398443222,\n  0.09722242504358292,\n  -0.1604766696691513,\n  0.04722120612859726,\n  0.010971685871481895,\n  -0.280223548412323,\n  0.17011362314224243,\n  -0.28260424733161926,\n  -0.1424885392189026,\n  -0.008311484940350056,\n  0.1257639080286026,\n  0.0763283222913742,\n  0.013646703213453293,\n  -0.0011771132703870535,\n  -0.004503345116972923,\n  -0.02854912541806698,\n  0.007557817734777927,\n  -0.024594826623797417,\n  -0.29378435015678406,\n  -0.16020478308200836,\n  0.03953518345952034,\n  0.12535084784030914,\n  -0.03475114703178406,\n  0.21489931643009186,\n  0.005640477407723665,\n  0.030687907710671425,\n  -0.2382674366235733,\n  0.1813691109418869,\n  -0.12370967119932175,\n  -0.007505051791667938,\n  0.24353289604187012,\n  0.1336391270160675,\n  -0.10651285201311111,\n  -0.07059162855148315,\n  -0.12635552883148193,\n  -0.05202184244990349,\n  0.08270379900932312,\n  -0.027409082278609276,\n  0.14471732079982758,\n  0.03512755408883095,\n  -0.003214897122234106,\n  0.008993780240416527,\n  -0.0244668647646904,\n  -0.10831718146800995,\n  0.033716414123773575,\n  0.04427638277411461,\n  -0.06446999311447144,\n  -0.04496452957391739,\n  -0.037421319633722305,\n  0.058811064809560776,\n  0.07326900213956833,\n  0.08534500747919083,\n  0.0599215030670166,\n  0.03575639799237251,\n  0.03260117769241333,\n  -0.04134087637066841,\n  -0.028613753616809845,\n  -0.16919675469398499,\n  0.10275418311357498,\n  -0.07816268503665924,\n  -0.05702567100524902,\n  0.12286335974931717,\n  -0.01871841587126255,\n  0.09722917526960373,\n  0.08227455615997314,\n  0.5109602212905884,\n  0.002772678853943944,\n  -0.16614528000354767,\n  -0.004863624460995197,\n  0.6654949188232422,\n  0.028638040646910667,\n  0.08009696751832962,\n  -0.11663080006837845,\n  0.015635935589671135,\n  -0.15309008955955505,\n  -0.035404983907938004,\n  -0.20069757103919983,\n  0.12879276275634766,\n  -0.030786026269197464,\n  -0.14113599061965942,\n  0.032279692590236664,\n  0.009613781236112118,\n  -1.2008345127105713,\n  0.03516306355595589,\n  0.0821518525481224,\n  0.09321863949298859,\n  -0.0038569988682866096,\n  -0.0536789707839489,\n  0.09828221797943115,\n  -0.02035222016274929,\n  0.04638248309493065,\n  0.2042870819568634,\n  0.542323112487793,\n  0.13531708717346191,\n  0.01298174262046814,\n  0.09227030724287033,\n  -0.1060345396399498,\n  -0.020722011104226112,\n  0.13738375902175903,\n  0.0853661373257637,\n  0.17063115537166595,\n  0.07701125741004944,\n  -0.040661972016096115,\n  -0.5219548940658569,\n  -0.08851370960474014,\n  0.03401524946093559,\n  0.0483589731156826,\n  -0.20465964078903198,\n  -0.03486023470759392,\n  0.13154156506061554,\n  0.5177139639854431,\n  -0.05972487851977348,\n  0.48390987515449524,\n  -0.06296516954898834,\n  0.21932372450828552,\n  0.06854142248630524,\n  0.020755518227815628,\n  -0.16412176191806793,\n  -0.23846712708473206,\n  0.05885384604334831,\n  0.04638566076755524,\n  0.0005140664870850742,\n  0.09267666935920715,\n  -0.05324641242623329,\n  0.08071522414684296,\n  0.07783183455467224,\n  -0.07001534849405289,\n  0.04776298627257347,\n  -0.06918460130691528,\n  -0.08114199340343475,\n  0.0035450360737740993,\n  -0.1481003612279892,\n  -0.014884350821375847,\n  0.2622561752796173,\n  0.04075797274708748,\n  -0.026880810037255287,\n  0.02988407574594021,\n  -0.017945386469364166,\n  0.03970895707607269,\n  0.09096984565258026,\n  0.14597749710083008,\n  0.02223227173089981,\n  -0.05049072951078415,\n  -0.07787881791591644,\n  -0.06273681670427322,\n  -0.00219557317905128,\n  -0.0043041459284722805,\n  0.026719603687524796,\n  0.0482567623257637,\n  0.5127128958702087,\n  0.07198896259069443,\n  -0.20667845010757446,\n  -0.09727619588375092,\n  -0.20184697210788727,\n  -0.03638001158833504,\n  0.15805290639400482,\n  0.15930920839309692,\n  -0.09257636219263077,\n  -0.1142825037240982,\n  -0.042244795709848404,\n  0.013052521273493767,\n  0.004834538325667381,\n  0.47538602352142334,\n  -0.20517946779727936,\n  -0.025121144950389862,\n  -0.027956636622548103,\n  -0.268799364566803,\n  0.032643940299749374,\n  0.08565749228000641,\n  -0.5102023482322693,\n  -0.012699945829808712,\n  0.005542519502341747,\n  -0.038348305970430374,\n  -0.22731518745422363,\n  -0.036665432155132294,\n  0.1426910012960434,\n  0.06097598373889923,\n  0.04562784731388092,\n  0.032868798822164536,\n  -0.033407486975193024,\n  -0.10637576878070831,\n  -0.05266011506319046,\n  -0.47399571537971497,\n  0.0403263121843338,\n  -0.06987228989601135,\n  0.030851997435092926,\n  0.1432642787694931,\n  -0.04985206946730614,\n  0.10069818049669266,\n  -0.05220986157655716,\n  -0.14757628738880157,\n  0.08173274993896484,\n  -0.002374690491706133,\n  0.29425951838493347,\n  0.06953155994415283,\n  0.0009733069455251098,\n  0.0202502254396677,\n  0.0813550055027008,\n  -0.3868407607078552,\n  0.07465069741010666,\n  0.04082806780934334,\n  0.25093820691108704,\n  -0.14609910547733307,\n  0.07479247450828552,\n  0.06810341030359268,\n  0.020887821912765503,\n  -0.0834665298461914,\n  0.024668248370289803,\n  -0.07083910703659058,\n  -0.0010841682087630033,\n  -0.01913909986615181,\n  0.08969731628894806,\n  -0.085547536611557,\n  -0.011757786385715008,\n  -0.0987459346652031,\n  -0.04417688399553299,\n  0.018805906176567078,\n  -0.04281844198703766,\n  0.0180769432336092,\n  0.07513993233442307,\n  0.17238804697990417,\n  -0.1622282713651657,\n  -0.03603704646229744,\n  -0.0633743405342102,\n  -0.2436802089214325,\n  -0.023449866101145744,\n  -0.05274614691734314,\n  0.07040050625801086,\n  -0.17302092909812927,\n  -0.11377774178981781,\n  0.12720629572868347,\n  -0.07583607733249664,\n  0.05088596045970917,\n  -0.0155176417902112,\n  0.013178910128772259,\n  -0.058048758655786514,\n  -0.028079332783818245,\n  0.016616810113191605,\n  0.004188932478427887,\n  0.2617841064929962,\n  -0.026896078139543533,\n  0.039824437350034714,\n  0.05159103870391846,\n  -0.4652523100376129,\n  -0.05751095712184906,\n  -0.1709182858467102,\n  0.03368359059095383,\n  0.09543269872665405,\n  0.18091098964214325,\n  -0.032310258597135544,\n  0.04003756865859032,\n  0.37216076254844666,\n  -0.006433289032429457,\n  -0.06630854308605194,\n  0.023503119125962257,\n  0.1437048763036728,\n  0.02568744122982025,\n  -0.30483806133270264,\n  0.0023122967686504126,\n  0.09953296929597855,\n  -0.1531481146812439,\n  0.21195726096630096,\n  0.05270301178097725,\n  0.09482026100158691,\n  0.42356443405151367,\n  -0.1428263783454895,\n  -0.03790956735610962,\n  0.01826825924217701,\n  -0.03825603052973747,\n  0.08655840158462524,\n  -0.008518056012690067,\n  -0.007623118814080954,\n  -0.26737403869628906,\n  -0.10958611220121384,\n  0.017032161355018616,\n  -0.05841181054711342,\n  0.3412078619003296,\n  -0.008091086521744728,\n  -0.058209557086229324,\n  -0.02445027604699135,\n  -0.027108797803521156,\n  -0.06031143665313721,\n  0.04808369278907776,\n  0.01690227910876274,\n  -0.11282456666231155,\n  -8.57377585816721e-07,\n  0.11876450479030609,\n  0.05591926723718643,\n  0.001173780532553792,\n  0.02684829942882061,\n  0.017663054168224335,\n  0.14299078285694122,\n  0.0756470113992691,\n  -0.03688295558094978,\n  0.17345698177814484,\n  0.26524773240089417,\n  0.006837673485279083,\n  -0.01157077495008707,\n  0.17763926088809967,\n  -0.15917232632637024,\n  -0.03704318404197693,\n  -0.04807180538773537,\n  -0.16546611487865448,\n  -0.10835471749305725,\n  0.1558912694454193,\n  0.10637304186820984,\n  -0.012083514593541622,\n  -0.020228328183293343,\n  0.19372037053108215,\n  -0.07900340110063553,\n  -0.0648702085018158,\n  0.15590260922908783,\n  0.05483821779489517,\n  -0.0021495188120752573,\n  0.025196334347128868,\n  0.025368686765432358,\n  0.09952904284000397,\n  0.030190182849764824,\n  0.07979335635900497,\n  -0.0020557900425046682,\n  -0.26858487725257874,\n  -0.3383607864379883,\n  0.025639409199357033,\n  -0.0313357338309288,\n  0.08335962146520615,\n  0.001142833149060607,\n  -0.0017040650127455592,\n  0.2614205777645111,\n  -0.08481540530920029,\n  -0.035743821412324905,\n  0.12557967007160187,\n  0.09244253486394882,\n  -0.1709032505750656,\n  0.1446399986743927,\n  0.0202887374907732,\n  -0.31398433446884155,\n  -0.3206214904785156,\n  -0.07816877216100693,\n  -0.006348433904349804,\n  0.03302041441202164,\n  0.10403288155794144,\n  -0.06874700635671616,\n  0.04126407206058502,\n  0.2596248686313629,\n  -0.09631247818470001,\n  -0.19114406406879425,\n  0.022670719772577286,\n  0.009582653641700745,\n  0.04066181927919388,\n  0.2884695529937744,\n  -0.046454545110464096,\n  -0.005812113638967276,\n  -0.00867356639355421,\n  0.051563821732997894,\n  0.06215030327439308,\n  0.10725037008523941,\n  -0.02436918579041958,\n  0.019858343526721,\n  0.058240555226802826,\n  -0.02388690412044525,\n  0.013978424482047558,\n  -0.07402929663658142,\n  0.19432342052459717,\n  -0.04824097082018852,\n  -0.11498317867517471,\n  -0.03607824817299843,\n  0.03401092812418938,\n  0.019148191437125206,\n  -0.17086687684059143,\n  -0.06787795573472977,\n  -0.07013054192066193,\n  -0.013705347664654255,\n  0.020678941160440445,\n  -0.22655662894248962,\n  -0.016418425366282463,\n  -0.11876160651445389,\n  0.00898120179772377,\n  0.12178824841976166,\n  -0.025057772174477577,\n  0.0075000012293457985,\n  -0.27187418937683105,\n  -0.09782305359840393,\n  0.004141749814152718,\n  0.08218331634998322,\n  -0.12138625979423523,\n  -0.06960423290729523,\n  0.052922286093235016,\n  -0.0049735987558960915,\n  0.05999996140599251,\n  0.008053092285990715,\n  0.016780385747551918,\n  -0.01790335588157177,\n  -0.002650306560099125,\n  0.004987497813999653,\n  0.02601306326687336,\n  0.028632933273911476,\n  0.025792697444558144,\n  -0.06511518359184265,\n  0.028560159727931023,\n  -0.13531219959259033,\n  -0.1348566859960556,\n  -0.09390702098608017,\n  0.5186141729354858,\n  0.33782759308815,\n  0.14122961461544037,\n  -0.3596705496311188,\n  0.24619324505329132,\n  -0.1362927109003067,\n  0.09790070354938507,\n  -0.00586475757881999,\n  -0.028975998982787132,\n  0.015525122173130512,\n  0.22567413747310638,\n  0.09186634421348572,\n  -0.06865072250366211,\n  0.1562604457139969,\n  0.0642654299736023,\n  0.18687979876995087,\n  0.007322285789996386,\n  0.22204595804214478,\n  0.07657438516616821,\n  0.0962369292974472,\n  0.043028153479099274,\n  0.030596263706684113,\n  -0.06790510565042496,\n  -0.022509507834911346,\n  0.12194481492042542,\n  -0.018140260130167007,\n  -0.00839230790734291,\n  -0.03069666214287281,\n  0.18410111963748932,\n  -0.189325749874115,\n  0.35362935066223145,\n  0.05824006721377373,\n  0.3049911558628082,\n  0.15127167105674744,\n  -0.16526898741722107,\n  0.10746148973703384,\n  0.044521741569042206,\n  0.007910452783107758,\n  -0.07297356426715851,\n  0.09447828680276871,\n  -0.05689693242311478,\n  0.09308499097824097,\n  0.019218122586607933,\n  0.001415063627064228,\n  -0.010416638106107712,\n  0.2013883739709854,\n  -0.06451427191495895,\n  -0.4919026792049408,\n  -0.06556989997625351,\n  0.19745942950248718,\n  0.07186702638864517,\n  0.1206963062286377,\n  -0.21303556859493256,\n  -0.012362176552414894,\n  -0.26898887753486633,\n  -0.007966048084199429,\n  -0.18515650928020477,\n  -0.11385807394981384,\n  0.04660505801439285,\n  -0.13621655106544495,\n  -0.04090964049100876,\n  -0.03184421733021736,\n  0.10773870348930359,\n  -0.05608852207660675,\n  -0.022791322320699692,\n  -0.026454096660017967,\n  0.05261227861046791,\n  0.012799503281712532,\n  -0.0841970220208168,\n  -0.016675865277647972,\n  0.05786152556538582,\n  0.0026899524964392185,\n  0.05744492635130882,\n  0.22099408507347107,\n  -0.05125311389565468,\n  0.061493657529354095,\n  0.05053730681538582,\n  -0.14406511187553406,\n  0.011219088919460773,\n  -0.02072140760719776,\n  -0.10905696451663971,\n  0.003375554922968149,\n  -0.11442174017429352]]"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"### Repeating the same for test dataset","metadata":{}},{"cell_type":"code","source":"# Load the Wav2Vec 2.0 model and processor\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\nmodel = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\n# Function to extract embeddings from audio data\ndef extract_embeddings(example):\n    audio_array = example['audio']['array']  # Extract audio array\n    sample_rate = example['audio']['sampling_rate']\n\n    # Resample if the sampling rate is not 16kHz\n    if sample_rate != 16000:\n        audio_array = torchaudio.transforms.Resample(sample_rate, 16000)(torch.tensor(audio_array))\n\n    # Process the waveform for the model\n    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n\n    # Extract embeddings\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Extract the last hidden state as embeddings (or pool if needed)\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n\n    # Add embeddings to the dataset\n    example['audio_embeddings'] = embeddings\n    return example\n\n\n# Map the embedding extraction function\ndataset_test = test_data.map(extract_embeddings)\n\n# Check output\n# print(dataset[0]['audio_embeddings'].shape)  # Expected output: (768,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:38:09.046659Z","iopub.execute_input":"2025-03-09T13:38:09.047016Z","iopub.status.idle":"2025-03-09T14:08:23.973698Z","shell.execute_reply.started":"2025-03-09T13:38:09.046962Z","shell.execute_reply":"2025-03-09T14:08:23.972725Z"}},"outputs":[{"name":"stderr","text":"Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8e44f9f16aa44adba7bbb74d0922bd4"}},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Adding the column Array(Audio)","metadata":{}},{"cell_type":"code","source":"dataset_train,dataset_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:41:58.666483Z","iopub.execute_input":"2025-03-09T14:41:58.666788Z","iopub.status.idle":"2025-03-09T14:41:58.672010Z","shell.execute_reply.started":"2025-03-09T14:41:58.666765Z","shell.execute_reply":"2025-03-09T14:41:58.671251Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_embeddings'],\n     num_rows: 1000\n }),\n Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_embeddings'],\n     num_rows: 2635\n }))"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"train_ = dataset_train\ntest_= dataset_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:42:08.772230Z","iopub.execute_input":"2025-03-09T14:42:08.772531Z","iopub.status.idle":"2025-03-09T14:42:08.776281Z","shell.execute_reply.started":"2025-03-09T14:42:08.772507Z","shell.execute_reply":"2025-03-09T14:42:08.775420Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import librosa\nimport numpy as np\nimport torch\n\n# Parameters for feature extraction\nSR = 16000     # Target sampling rate\nN_MFCC = 13    # Number of MFCC features\nN_MELS = 128   # Number of Mel bands\nN_FFT = 1024   # FFT window size\nHOP_LENGTH = 512  # Hop size for overlapping segments\n\n# Combined feature extraction function\ndef extract_audio_features(batch):\n    audio_data = batch['audio']['array']\n    sampling_rate = batch['audio']['sampling_rate']\n\n    # Resample to target sampling rate\n    if sampling_rate != SR:\n        audio_data = librosa.resample(audio_data, orig_sr=sampling_rate, target_sr=SR)\n    \n    # MFCC Features\n    mfcc_features = librosa.feature.mfcc(y=audio_data, sr=SR, n_mfcc=N_MFCC)\n\n    # Mel-spectrogram\n    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)  # Convert to decibel scale\n\n    # Chroma Features\n    chroma_features = librosa.feature.chroma_stft(y=audio_data, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH)\n\n    # Spectrogram\n    spectrogram = np.abs(librosa.stft(audio_data, n_fft=N_FFT, hop_length=HOP_LENGTH))\n\n    # Flatten and combine features\n    combined_features = np.concatenate([\n        mfcc_features.T,               # Shape: (Time, N_MFCC)\n        mel_spectrogram_db.T,          # Shape: (Time, N_MELS)\n        chroma_features.T,             # Shape: (Time, 12)\n        spectrogram.T                  # Shape: (Time, Freq Bins)\n    ], axis=1)                         # Combined shape: (Time, Total Features)\n\n    # Convert to PyTorch tensor\n    batch['combined_features'] = torch.tensor(combined_features, dtype=torch.float32)\n    \n    return batch\n\n# Apply the function to your dataset\ntest_ = test_.map(extract_audio_features, remove_columns=[\"audio\"])\ntrain_ = train_.map(extract_audio_features, remove_columns=[\"audio\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:42:31.389431Z","iopub.execute_input":"2025-03-09T14:42:31.389733Z","iopub.status.idle":"2025-03-09T14:45:02.332763Z","shell.execute_reply.started":"2025-03-09T14:42:31.389707Z","shell.execute_reply":"2025-03-09T14:45:02.331768Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0dc5768c40e40f8a504a0bbed1ce2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3d78ba820714ba2950bc8237db47439"}},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"Y = train_['is_tts']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:45:57.037947Z","iopub.execute_input":"2025-03-09T14:45:57.038375Z","iopub.status.idle":"2025-03-09T14:45:57.043639Z","shell.execute_reply.started":"2025-03-09T14:45:57.038347Z","shell.execute_reply":"2025-03-09T14:45:57.042784Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"test_= test_.remove_columns(['text', 'id', 'language','is_tts'])\ntrain_= train_.remove_columns(['text', 'id', 'language','is_tts'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:46:30.827152Z","iopub.execute_input":"2025-03-09T14:46:30.827457Z","iopub.status.idle":"2025-03-09T14:46:30.835603Z","shell.execute_reply.started":"2025-03-09T14:46:30.827432Z","shell.execute_reply":"2025-03-09T14:46:30.834906Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"test_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:54:14.471793Z","iopub.execute_input":"2025-03-09T14:54:14.472110Z","iopub.status.idle":"2025-03-09T14:54:14.477099Z","shell.execute_reply.started":"2025-03-09T14:54:14.472086Z","shell.execute_reply":"2025-03-09T14:54:14.476339Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['audio_embeddings', 'combined_features'],\n    num_rows: 2635\n})"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Extracting features and embeddings\ncombined_features = [np.mean(sample['combined_features'], axis=0) for sample in train_]  # Averaging across time steps\naudio_embeddings = [sample['audio_embeddings'] for sample in train_]\n\n# Creating DataFrame\ndf = pd.DataFrame({\n    'combined_features': combined_features,\n    'audio_embeddings': audio_embeddings\n})\n\n# Expanding nested arrays into separate columns for better usability\ncombined_features_df = pd.DataFrame(df['combined_features'].tolist(), columns=[f'feat_{i}' for i in range(len(combined_features[0]))])\naudio_embeddings_df = pd.DataFrame(df['audio_embeddings'].tolist(), columns=[f'emb_{i}' for i in range(len(audio_embeddings[0]))])\n\n# Final DataFrame combining both\nfinal_df = pd.concat([combined_features_df, audio_embeddings_df], axis=1)\n\nprint(final_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:07:14.231870Z","iopub.execute_input":"2025-03-09T15:07:14.232199Z","iopub.status.idle":"2025-03-09T15:09:17.429231Z","shell.execute_reply.started":"2025-03-09T15:07:14.232171Z","shell.execute_reply":"2025-03-09T15:09:17.428437Z"}},"outputs":[{"name":"stdout","text":"       feat_0     feat_1     feat_2     feat_3     feat_4     feat_5  \\\n0 -275.100198  60.389802 -24.322762 -14.280791 -25.368571   0.607699   \n1 -304.220673  71.421312  -9.828331   8.338161 -13.421920 -22.876770   \n2 -312.147800  81.370709  -2.344214  14.622457  -6.629311  10.500782   \n3 -224.705771  92.893843  -7.904644  38.332583  -8.676477   3.278054   \n4 -201.752393  89.870630  -4.589692  35.805198 -21.589034  -8.478465   \n\n      feat_6     feat_7     feat_8     feat_9  ...   emb_758   emb_759  \\\n0 -18.978388 -19.762101 -10.515368  -1.691420  ...  0.276164 -0.051486   \n1  -2.347643 -21.418916 -19.963772 -10.545296  ...  0.221822 -0.050940   \n2  -6.593125  -6.817249  -8.016429   5.758780  ...  0.232978 -0.049856   \n3 -10.970217 -12.758895 -20.125765   3.231862  ...  0.198349 -0.050375   \n4   6.272365 -25.483747   5.307291 -13.415708  ...  0.217852 -0.045718   \n\n    emb_760   emb_761   emb_762   emb_763   emb_764   emb_765   emb_766  \\\n0 -0.057750  0.021381 -0.251923  0.008775 -0.015292 -0.158975  0.043506   \n1  0.055572  0.025302 -0.223837  0.016384 -0.017741 -0.195638 -0.000930   \n2 -0.033677  0.144080 -0.283921  0.007623 -0.011432 -0.286605 -0.007541   \n3 -0.011669  0.103771 -0.156226  0.013771 -0.020455 -0.123268  0.006224   \n4  0.111635 -0.063635 -0.132326  0.018184 -0.007966  0.006059 -0.058253   \n\n    emb_767  \n0 -0.024008  \n1 -0.086700  \n2 -0.037552  \n3 -0.069254  \n4 -0.097785  \n\n[5 rows x 1434 columns]\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Extracting features and embeddings\ncombined_features = [np.mean(sample['combined_features'], axis=0) for sample in test_]  # Averaging across time steps\naudio_embeddings = [sample['audio_embeddings'] for sample in test_]\n\n# Creating DataFrame\ndf = pd.DataFrame({\n    'combined_features': combined_features,\n    'audio_embeddings': audio_embeddings\n})\n\n# Expanding nested arrays into separate columns for better usability\ncombined_features_df = pd.DataFrame(df['combined_features'].tolist(), columns=[f'feat_{i}' for i in range(len(combined_features[0]))])\naudio_embeddings_df = pd.DataFrame(df['audio_embeddings'].tolist(), columns=[f'emb_{i}' for i in range(len(audio_embeddings[0]))])\n\n# Final DataFrame combining both\ntest_df = pd.concat([combined_features_df, audio_embeddings_df], axis=1)\n\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:12:15.619143Z","iopub.execute_input":"2025-03-09T15:12:15.619462Z","iopub.status.idle":"2025-03-09T15:17:31.593926Z","shell.execute_reply.started":"2025-03-09T15:12:15.619438Z","shell.execute_reply":"2025-03-09T15:17:31.593012Z"}},"outputs":[{"name":"stdout","text":"       feat_0     feat_1     feat_2     feat_3     feat_4    feat_5  \\\n0 -323.679991  76.520725 -12.137748  14.131280 -25.446220  4.976515   \n1 -345.252255  82.258486 -13.390476   9.848259 -23.343344  6.942505   \n2 -370.560773  59.250755 -19.189193  18.276547 -24.782527  5.977365   \n3 -349.805191  87.443112 -10.931218  19.521460 -16.039356  7.323803   \n4 -329.224893  68.345302  -5.554238  29.161562 -21.079068  4.911482   \n\n      feat_6     feat_7     feat_8    feat_9  ...   emb_758   emb_759  \\\n0 -14.923873  -9.487348 -15.419669 -1.593292  ...  0.271766 -0.048944   \n1 -15.918027  -6.746600 -10.526957  1.653832  ...  0.240013 -0.051273   \n2 -14.447390  -7.055883 -11.126095 -0.680792  ...  0.286856 -0.049341   \n3 -15.130816 -10.561822 -13.100427  1.293102  ...  0.226894 -0.049158   \n4 -14.557055 -15.596798 -16.979532 -2.232384  ...  0.247417 -0.049806   \n\n    emb_760   emb_761   emb_762   emb_763   emb_764   emb_765   emb_766  \\\n0  0.062750  0.082348 -0.178057  0.008677 -0.014246 -0.121198  0.000650   \n1 -0.023606  0.218243 -0.196668  0.007950 -0.015522 -0.188419  0.001653   \n2 -0.166667  0.209754 -0.226506  0.008769 -0.011772 -0.197840  0.024594   \n3 -0.066075  0.095614 -0.217121  0.012251 -0.016012 -0.131367  0.007340   \n4  0.005209  0.181516 -0.210943  0.011856 -0.016376 -0.131380 -0.012028   \n\n    emb_767  \n0 -0.022611  \n1 -0.010405  \n2  0.027040  \n3 -0.008328  \n4 -0.071848  \n\n[5 rows x 1434 columns]\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit and transform the data\nscaled_features = scaler.fit_transform(final_df)\n# scaled_features_test = scaler.fit_transform(test_df)\n# Convert back to DataFrame for easier handling\nscaled_df = pd.DataFrame(scaled_features, columns=final_df.columns)\n\nprint(scaled_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:27:34.867756Z","iopub.execute_input":"2025-03-09T15:27:34.868144Z","iopub.status.idle":"2025-03-09T15:27:34.944030Z","shell.execute_reply.started":"2025-03-09T15:27:34.868114Z","shell.execute_reply":"2025-03-09T15:27:34.943232Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"     feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n0  0.759401 -1.339371 -1.347096 -3.078612 -1.413730  0.495651 -1.277343   \n1  0.271610 -0.716851 -0.382233 -1.275815 -0.290464 -2.742033  0.372657   \n2  0.138825 -0.155396  0.115969 -0.774939  0.348201  1.859559 -0.048554   \n3  1.603546  0.494866 -0.254177  1.114828  0.155719  0.863799 -0.482822   \n4  1.988033  0.324263 -0.033508  0.913388 -1.058364 -0.757012  1.227880   \n\n     feat_7    feat_8    feat_9  ...   emb_758   emb_759   emb_760   emb_761  \\\n0 -0.537328 -0.598798  0.781589  ...  1.262320 -0.005807 -0.966926 -0.853989   \n1 -0.747045 -1.824034 -0.522337  ... -0.408890  0.337722  0.977311 -0.815554   \n2  1.101210 -0.274745  1.878794  ... -0.065793  1.019208 -0.553920  0.348859   \n3  0.349126 -1.845040  1.506650  ... -1.130762  0.692930 -0.176321 -0.046301   \n4 -1.261565  1.453028 -0.945068  ... -0.530989  3.620143  1.939166 -1.687422   \n\n    emb_762   emb_763   emb_764   emb_765   emb_766   emb_767  \n0 -0.632392 -0.018545  0.150067 -0.374389  2.373752  0.901650  \n1 -0.069594  1.699987 -0.644470 -0.990732 -0.129575 -0.513949  \n2 -1.273587 -0.278849  1.402822 -2.519951 -0.502033  0.595825  \n3  1.285231  1.109831 -1.524959  0.225870  0.273431 -0.120011  \n4  1.764167  2.106474  2.527421  2.399966 -3.358923 -0.764253  \n\n[5 rows x 1434 columns]\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"# Assuming 'scaler' was fitted on the training data\nscaled_test_features = scaler.transform(test_df)\n\n# Convert back to DataFrame for consistency\nscaled_test_df = pd.DataFrame(scaled_test_features, columns=test_df.columns)\n\nprint(scaled_test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:27:52.966772Z","iopub.execute_input":"2025-03-09T15:27:52.967190Z","iopub.status.idle":"2025-03-09T15:27:53.041266Z","shell.execute_reply.started":"2025-03-09T15:27:52.967154Z","shell.execute_reply":"2025-03-09T15:27:53.039894Z"}},"outputs":[{"name":"stdout","text":"     feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n0 -0.054348 -0.429086 -0.535966 -0.814087 -1.421030  1.097957 -0.875079   \n1 -0.415700 -0.105298 -0.619357 -1.155456 -1.223311  1.368998 -0.973713   \n2 -0.839638 -1.403648 -1.005365 -0.483697 -1.358628  1.235939 -0.827805   \n3 -0.491966  0.187276 -0.455650 -0.384474 -0.536564  1.421566 -0.895611   \n4 -0.147230 -0.890434 -0.097716  0.383870 -1.010416  1.088991 -0.838686   \n\n     feat_7    feat_8    feat_9  ...   emb_758   emb_759   emb_760   emb_761  \\\n0  0.763234 -1.234771  0.796041  ...  1.127047  1.592127  1.100461 -0.256315   \n1  1.110153 -0.600301  1.274251  ...  0.150552  0.128029 -0.381122  1.075893   \n2  1.071004 -0.677995  0.930426  ...  1.591111  1.342377 -2.835577  0.992675   \n3  0.627228 -0.934019  1.221125  ... -0.252909  1.457434 -1.109756 -0.126271   \n4 -0.010091 -1.437048  0.701921  ...  0.378231  1.050131  0.113246  0.715848   \n\n    emb_762   emb_763   emb_764   emb_765   emb_766   emb_767  \n0  0.847773 -0.040855  0.489475  0.260672 -0.040587  0.933212  \n1  0.474833 -0.205062  0.075499 -0.869367  0.015898  1.208814  \n2 -0.123071 -0.020036  1.292212 -1.027751  1.308308  2.054341  \n3  0.064999  0.766458 -0.083607  0.089720  0.336290  1.255716  \n4  0.188794  0.677296 -0.201521  0.089508 -0.754804 -0.178572  \n\n[5 rows x 1434 columns]\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"Y[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:45:00.518753Z","iopub.execute_input":"2025-03-09T15:45:00.519066Z","iopub.status.idle":"2025-03-09T15:45:00.523996Z","shell.execute_reply.started":"2025-03-09T15:45:00.519040Z","shell.execute_reply":"2025-03-09T15:45:00.523119Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\n# Initialize the XGBoost Classifier\nmodel = xgb.XGBClassifier(\n    objective='binary:logistic',\n    eval_metric='logloss',\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\n# Train the model on scaled data\nmodel.fit(scaled_df, Y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:52:02.412723Z","iopub.execute_input":"2025-03-09T15:52:02.413197Z","iopub.status.idle":"2025-03-09T15:52:14.195656Z","shell.execute_reply.started":"2025-03-09T15:52:02.413158Z","shell.execute_reply":"2025-03-09T15:52:14.194723Z"}},"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nmodel_lgbm = LGBMClassifier(\n    objective='binary',\n    metric='binary_logloss',\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\nmodel_lgbm.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:54:32.824795Z","iopub.execute_input":"2025-03-09T15:54:32.825135Z","iopub.status.idle":"2025-03-09T15:54:45.477157Z","shell.execute_reply.started":"2025-03-09T15:54:32.825110Z","shell.execute_reply":"2025-03-09T15:54:45.476253Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 460, number of negative: 540\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026606 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 365670\n[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 1434\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.460000 -> initscore=-0.160343\n[LightGBM] [Info] Start training from score -0.160343\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(max_depth=6, metric='binary_logloss', n_estimators=200,\n               objective='binary', random_state=42)","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=6, metric=&#x27;binary_logloss&#x27;, n_estimators=200,\n               objective=&#x27;binary&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=6, metric=&#x27;binary_logloss&#x27;, n_estimators=200,\n               objective=&#x27;binary&#x27;, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nmodel_gb = GradientBoostingClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\nmodel_gb.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:44.951651Z","iopub.execute_input":"2025-03-09T15:58:44.951999Z","iopub.status.idle":"2025-03-09T16:01:04.871562Z","shell.execute_reply.started":"2025-03-09T15:58:44.951947Z","shell.execute_reply":"2025-03-09T16:01:04.870549Z"}},"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"GradientBoostingClassifier(max_depth=6, n_estimators=200, random_state=42)","text/html":"<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=6, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=6, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":131},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nmodel_ab = AdaBoostClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    random_state=42\n)\nmodel_ab.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:03:25.576811Z","iopub.execute_input":"2025-03-09T16:03:25.577165Z","iopub.status.idle":"2025-03-09T16:03:58.110412Z","shell.execute_reply.started":"2025-03-09T16:03:25.577135Z","shell.execute_reply":"2025-03-09T16:03:58.109450Z"}},"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)","text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":136},{"cell_type":"code","source":"y_pred_proba = model_ab.predict_proba(scaled_test_df)[:, 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:03:58.111723Z","iopub.execute_input":"2025-03-09T16:03:58.112081Z","iopub.status.idle":"2025-03-09T16:03:59.023477Z","shell.execute_reply.started":"2025-03-09T16:03:58.112047Z","shell.execute_reply":"2025-03-09T16:03:59.022767Z"}},"outputs":[],"execution_count":137},{"cell_type":"code","source":"round(y_pred_proba,3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:55:56.523486Z","iopub.execute_input":"2025-03-09T15:55:56.523782Z","iopub.status.idle":"2025-03-09T15:55:56.599529Z","shell.execute_reply.started":"2025-03-09T15:55:56.523759Z","shell.execute_reply":"2025-03-09T15:55:56.598426Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-3acccf43a2d6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: type numpy.ndarray doesn't define __round__ method"],"ename":"TypeError","evalue":"type numpy.ndarray doesn't define __round__ method","output_type":"error"}],"execution_count":118},{"cell_type":"code","source":"test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:52:14.347851Z","iopub.execute_input":"2025-03-09T15:52:14.348086Z","iopub.status.idle":"2025-03-09T15:52:14.363016Z","shell.execute_reply.started":"2025-03-09T15:52:14.348067Z","shell.execute_reply":"2025-03-09T15:52:14.362220Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'id', 'language', 'is_tts', 'audio'],\n    num_rows: 2635\n})"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"y_pred[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:52:14.363835Z","iopub.execute_input":"2025-03-09T15:52:14.364074Z","iopub.status.idle":"2025-03-09T15:52:14.379582Z","shell.execute_reply.started":"2025-03-09T15:52:14.364056Z","shell.execute_reply":"2025-03-09T15:52:14.378916Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"array([0.24066556, 0.75933444], dtype=float32)"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Ensure y_pred is 1D\n# y_pred_proba = np.ravel(y_pred)  # Flattens to 1D if it's 2D\n\n# Create DataFrame\nresults_df = pd.DataFrame({\n    'id': test_data['id'],  # Extract 'id' from test_data\n    'is_tts': y_pred_proba\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:03:59.025018Z","iopub.execute_input":"2025-03-09T16:03:59.025252Z","iopub.status.idle":"2025-03-09T16:03:59.032773Z","shell.execute_reply.started":"2025-03-09T16:03:59.025233Z","shell.execute_reply":"2025-03-09T16:03:59.031949Z"}},"outputs":[],"execution_count":138},{"cell_type":"code","source":"results_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:03:59.033622Z","iopub.execute_input":"2025-03-09T16:03:59.033892Z","iopub.status.idle":"2025-03-09T16:03:59.046906Z","shell.execute_reply.started":"2025-03-09T16:03:59.033861Z","shell.execute_reply":"2025-03-09T16:03:59.046046Z"}},"outputs":[{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"(2635, 2)"},"metadata":{}}],"execution_count":139},{"cell_type":"code","source":"results_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:03:59.047840Z","iopub.execute_input":"2025-03-09T16:03:59.048150Z","iopub.status.idle":"2025-03-09T16:03:59.067280Z","shell.execute_reply.started":"2025-03-09T16:03:59.048122Z","shell.execute_reply":"2025-03-09T16:03:59.066656Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}