{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":95302,"databundleVersionId":11325230,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Official dataset for this challenge\ndataset = load_dataset(\"SherryT997/IndicTTS-Deepfake-Challenge-Data\")  \n\n# Train and test splits\ntrain_data = dataset[\"train\"] \ntest_data = dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:57:46.059368Z","iopub.execute_input":"2025-03-10T14:57:46.059676Z","iopub.status.idle":"2025-03-10T15:02:15.624807Z","shell.execute_reply.started":"2025-03-10T14:57:46.059641Z","shell.execute_reply":"2025-03-10T15:02:15.623913Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4fff2fdd3d4cf4b4a589295225b092"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46725fc3d9474db88d20ef27f8feabd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c9eb76a98447ecbadc3b5d1826f58c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/35 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18852e4d7c204e36bafb13997c494cbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00035.parquet:   0%|          | 0.00/453M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a433e490054cfe8847c6b0ed8e8e6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00035.parquet:   0%|          | 0.00/461M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e54381b24c314001ac30764ff0fe0a6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00035.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4c5761cb844e8db889c2d6b59b3ed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00035.parquet:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9711d70d468a4f6fac0925ab60de46a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00035.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a7b680b4a244152b8ce7c6ba29e5205"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00035.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382ec103ca90478790daa04efdd2e63d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00035.parquet:   0%|          | 0.00/447M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6f1f49a345445d885c923c2c2656f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00035.parquet:   0%|          | 0.00/516M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9afc4223a2b4acba2dd70e1e3cee37d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00035.parquet:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96221119ea554e7b8ec1f3789b47ee41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00035.parquet:   0%|          | 0.00/521M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22272b4d43c64ac88b25da2899fe53a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00035.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b40508c22114e5ea5d38d200254ecc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00035.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc8b58637aa4048827ecd7f306cb449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00035.parquet:   0%|          | 0.00/414M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52c7f74d8d874e889b59de68c84a6e9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00035.parquet:   0%|          | 0.00/473M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be071503e1d04088ab1148f605960f17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00035.parquet:   0%|          | 0.00/481M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c61864ea34d42c0bb61e999f644b9f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00035.parquet:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70afa4ba5f5a411d99f3caefd87acf01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00035.parquet:   0%|          | 0.00/532M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cab1a7f41b34953b552c02ff93d7cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00035.parquet:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ff25adb5e8c412b9c5c1a754d50dbce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00035.parquet:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb43add0573d442f8a41040f333c80e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00035.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1690aeefb82341a2bb56550b18f27255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00035.parquet:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716ba3f1af44474e9c72f02ad57b27a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00035.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b787a501bf46ce860fc99c3e92f022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00035.parquet:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28894f528e214264ac141e3f0a3bbb6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00035.parquet:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bdcb8416540463b9599a21c0034a8ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00035.parquet:   0%|          | 0.00/576M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9093216191b4476a15dad4b7403562f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00035.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f63a02fef604dca81393fdaf7ba63c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00035.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f821b26844194cd1aedb124273abdd2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00035.parquet:   0%|          | 0.00/421M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9489ea8745de406497bd79ecb03c6056"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00035.parquet:   0%|          | 0.00/382M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60291d5d1d85407d81eb1382f655bb5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00035.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e55cb01ab3d742ed8cca46d6d2437669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00030-of-00035.parquet:   0%|          | 0.00/282M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dd8342f7daa4c01866b8f17b062f626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00031-of-00035.parquet:   0%|          | 0.00/688M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8696f2a8d2545d5812574c9d00b0022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00032-of-00035.parquet:   0%|          | 0.00/613M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a06dd20a10401bb0cc5619aa9184bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00033-of-00035.parquet:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f8f59b2f89643979f08fa0d4203b46b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00034-of-00035.parquet:   0%|          | 0.00/424M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad4a003cca35495198f33519b06bc973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00004.parquet:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4915ecaa134b15ae2aa35ad39d7b0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00001-of-00004.parquet:   0%|          | 0.00/364M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2aa23f998364e2ea165be80a59307fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00002-of-00004.parquet:   0%|          | 0.00/410M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe52f51de435479885936b2e43512255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00003-of-00004.parquet:   0%|          | 0.00/291M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6aee3d23160478494ee9514afb3e508"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/31102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"563e080312814892ba9293bc0f03b0f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"087a91c3e419437ea3e88f92b69d82fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"483848f5a42c41f382c0df0737add49b"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"train_data[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_sample = train_data.select(range(30000))  # First 91 rows (index 0 to 90)\n# test_sample = train_data.select(range(30001, 31102))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_sample = train_data\ntest_sample = test_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_sample","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport librosa\nfrom sklearn.metrics import roc_auc_score\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom datasets import load_dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_from_array(audio_array, sr=16000, n_mels=40, duration=2):\n    # Ensure the audio is of the correct length (duration x sampling rate)\n    audio = audio_array[:sr * duration]\n    \n    # Compute Mel-spectrogram\n    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n    \n    # Convert to dB scale (logarithmic scale)\n    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n    \n    return mel_spectrogram.T  # Transpose to have time as the first axis\n\n# Padding function to make all Mel-spectrograms the same size\ndef pad_features(features, target_length):\n    # Pad sequences to the target length\n    return np.pad(features, ((0, target_length - features.shape[0]), (0, 0)), mode='constant', constant_values=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = []\ny_train = []\nX_test = []\ny_test = []\n\ntarget_time_steps = 130","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for sample in train_sample:\n    audio_array = sample['audio']['array']\n    label = sample['is_tts']\n    \n    # Extract features and append to training set\n    mel_spec = extract_features_from_array(audio_array)\n    X_train.append(pad_features(mel_spec, target_time_steps))  # Pad features\n    y_train.append(label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for sample in test_sample:\n    audio_array = sample['audio']['array']\n    label = sample['is_tts']\n    \n    # Extract features and append to test set\n    mel_spec = extract_features_from_array(audio_array)\n    X_test.append(pad_features(mel_spec, target_time_steps))  # Pad features\n    y_test.append(label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_train[..., np.newaxis]  # Adding a channel axis for CNN\nX_test = X_test[..., np.newaxis]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_pred_prob = model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_prob = model.predict(X_test)[:, 0] ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': [sample['id'] for sample in test_data], \n    'is_tts': y_pred_prob \n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(submission.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# roc_auc = roc_auc_score(y_test, y_pred_prob)\n# print(f'ROC-AUC Score: {roc_auc}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchaudio.transforms as T\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n\n# Shuffle the dataset\ntrain_data = train_data.shuffle(seed=42)\n\n# Split train_data into train and validation sets manually\nsplit_idx = int(0.9 * len(train_data))  # 90% train, 10% validation\ntrain_data_split = train_data.select(range(split_idx))\nval_data_split = train_data.select(range(split_idx, len(train_data)))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:18.775686Z","iopub.execute_input":"2025-03-10T15:05:18.776418Z","iopub.status.idle":"2025-03-10T15:05:18.822505Z","shell.execute_reply.started":"2025-03-10T15:05:18.776377Z","shell.execute_reply":"2025-03-10T15:05:18.821673Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"spectrogram_transform = T.MelSpectrogram(sample_rate=16000, n_mels=128)\n\ndef processing_audio(batch):\n    waveform = torch.tensor(batch[\"audio\"][\"array\"], dtype=torch.float32)\n    max_length = 16000\n    \n    # Pad or truncate audio\n    waveform = F.pad(waveform, (0, max_length - waveform.shape[0])) if waveform.shape[0] < max_length else waveform[:max_length]\n    \n    # Convert to spectrogram\n    spectrogram = spectrogram_transform(waveform)  # [128, T]\n    \n    # Ensure time dimension consistency\n    spectrogram = F.pad(spectrogram, (0, 128 - spectrogram.shape[1])) if spectrogram.shape[1] < 128 else spectrogram[:, :128]\n    \n    batch[\"spectrogram\"] = spectrogram.numpy()  # Convert to NumPy before storing\n    batch[\"labels\"] = batch[\"is_tts\"]\n    return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:11:58.510232Z","iopub.execute_input":"2025-03-10T17:11:58.510622Z","iopub.status.idle":"2025-03-10T17:11:58.520663Z","shell.execute_reply.started":"2025-03-10T17:11:58.510587Z","shell.execute_reply":"2025-03-10T17:11:58.519649Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Custom Dataset Class\n# Custom Dataset Class\nclass AudioDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        spectrogram = torch.tensor(self.dataset[idx][\"spectrogram\"], dtype=torch.float32)  # [128, 128]\n        spectrogram = spectrogram.unsqueeze(0)  # Add channel dimension: [1, 128, 128]\n        label = torch.tensor(self.dataset[idx][\"labels\"], dtype=torch.float32) if self.dataset[idx][\"labels\"] is not None else None\n        return spectrogram, label, self.dataset[idx][\"id\"]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:11:59.219130Z","iopub.execute_input":"2025-03-10T17:11:59.219489Z","iopub.status.idle":"2025-03-10T17:11:59.224912Z","shell.execute_reply.started":"2025-03-10T17:11:59.219454Z","shell.execute_reply":"2025-03-10T17:11:59.224003Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Enhanced CNN Model Definition\nclass AudioCNN(nn.Module):\n    def __init__(self):\n        super(AudioCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.batch_norm1 = nn.BatchNorm2d(64)\n        self.batch_norm2 = nn.BatchNorm2d(128)\n        self.batch_norm3 = nn.BatchNorm2d(256)\n        self.dropout = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(256 * 8 * 8, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 1)\n    \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.batch_norm1(self.conv2(x))))\n        x = self.pool(F.relu(self.batch_norm2(self.conv3(x))))\n        x = self.pool(F.relu(self.batch_norm3(self.conv4(x))))\n    \n        #print(x.shape)  # Debugging step to check shape before flattening\n\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.fc3(x)\n        return x\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:12:01.363066Z","iopub.execute_input":"2025-03-10T17:12:01.363389Z","iopub.status.idle":"2025-03-10T17:12:01.371699Z","shell.execute_reply.started":"2025-03-10T17:12:01.363362Z","shell.execute_reply":"2025-03-10T17:12:01.370762Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Apply preprocessing to dataset\ntrain_dataset = train_data_split.map(processing_audio, remove_columns=[\"audio\", \"text\", \"language\", \"is_tts\"])\nval_dataset = val_data_split.map(processing_audio, remove_columns=[\"audio\", \"text\", \"language\", \"is_tts\"])\ntest_dataset = test_data.map(processing_audio, remove_columns=[\"audio\", \"text\", \"language\"])\n\n# Create DataLoaders\ntrain_loader = DataLoader(AudioDataset(train_dataset), batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(AudioDataset(val_dataset), batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(AudioDataset(test_dataset), batch_size=32, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:12:02.936410Z","iopub.execute_input":"2025-03-10T17:12:02.936737Z","iopub.status.idle":"2025-03-10T17:12:02.973692Z","shell.execute_reply.started":"2025-03-10T17:12:02.936713Z","shell.execute_reply":"2025-03-10T17:12:02.973003Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Initialize Model\nmodel = AudioCNN().to(device, memory_format=torch.channels_last)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:12:05.032438Z","iopub.execute_input":"2025-03-10T17:12:05.032758Z","iopub.status.idle":"2025-03-10T17:12:05.081019Z","shell.execute_reply.started":"2025-03-10T17:12:05.032735Z","shell.execute_reply":"2025-03-10T17:12:05.080332Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"AudioCNN(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"# Define Loss and Optimizer\ncriterion = torch.nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:12:06.829460Z","iopub.execute_input":"2025-03-10T17:12:06.829759Z","iopub.status.idle":"2025-03-10T17:12:06.833905Z","shell.execute_reply.started":"2025-03-10T17:12:06.829735Z","shell.execute_reply":"2025-03-10T17:12:06.833095Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"scaler = torch.amp.GradScaler(\"cuda\")\n\nnum_epochs = 5\nstart_time = time.time()  # Start timing\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    epoch_start = time.time()\n\n    for batch in train_loader:\n        spectrograms, labels, _ = batch\n        spectrograms, labels = spectrograms.to(device), labels.to(device).unsqueeze(1)\n        \n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():  # Enable mixed precision\n            outputs = model(spectrograms)\n            loss = criterion(outputs, labels)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n    \n    epoch_loss = running_loss / len(train_loader)  \n    epoch_time = time.time() - epoch_start  \n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Time: {epoch_time:.2f} sec\")\n# Compute total training time\ntotal_time = time.time() - start_time\nprint(f\"Total training time for {num_epochs} epochs: {total_time:.2f} sec ({total_time/60:.2f} min)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:24:15.276412Z","iopub.status.idle":"2025-03-10T17:24:15.276710Z","shell.execute_reply":"2025-03-10T17:24:15.276607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on validation set\nmodel.eval()\nval_loss = 0.0\nwith torch.no_grad():\n    for batch in val_loader:\n        spectrograms, labels, _ = batch\n        spectrograms, labels = spectrograms.to(device), labels.to(device).unsqueeze(1)\n\n        outputs = model(spectrograms)  # Outputs are logits\n        loss = criterion(outputs, labels)  # BCEWithLogitsLoss expects logits\n        \n        val_loss += loss.item()\n\nval_loss /= len(val_loader)\nprint(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:24:20.026172Z","iopub.execute_input":"2025-03-10T17:24:20.026517Z","iopub.status.idle":"2025-03-10T17:25:05.953001Z","shell.execute_reply.started":"2025-03-10T17:24:20.026489Z","shell.execute_reply":"2025-03-10T17:25:05.952015Z"}},"outputs":[{"name":"stdout","text":"Epoch [2/5], Loss: 0.6172, Val Loss: 0.5551\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"# Predict Probabilities for Test Data\nmodel.eval()\ny_probs, y_ids = [], []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        spectrograms, _, ids = batch\n        spectrograms = spectrograms.to(device)\n        \n        outputs = model(spectrograms)  # Logits\n        probs = torch.sigmoid(outputs)  # Convert to probabilities\n        \n        # Convert to Python list with rounded values\n        probs = [round(p.item(), 3) for p in probs.flatten()]  \n        \n        y_probs.extend(probs)\n        y_ids.extend(ids)\n\n# Create submission.csv\nsubmission_df = pd.DataFrame({\"id\": y_ids, \"is_tts\": y_probs})\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:29:10.291723Z","iopub.execute_input":"2025-03-10T17:29:10.292098Z","iopub.status.idle":"2025-03-10T17:29:48.912401Z","shell.execute_reply.started":"2025-03-10T17:29:10.292069Z","shell.execute_reply":"2025-03-10T17:29:48.911189Z"}},"outputs":[{"name":"stdout","text":"submission.csv saved successfully!\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Predict Probabilities for Test Data\nmodel.eval()\ny_probs, y_ids = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        spectrograms, _, ids = batch\n        spectrograms = spectrograms.to(device)\n        \n        outputs = model(spectrograms)\n        probs = torch.sigmoid(outputs)  # Apply sigmoid manually to convert logits to probabilities\n\n          # Probability of being synthetic (is_tts = 1), rounded to 3 decimal places\n        probs = round(probs[0, 1], 3)\n        \n        y_probs.extend(probs.cpu().numpy().flatten().tolist())\n        y_ids.extend(ids)\n\n# Create submission.csv\nsubmission_df = pd.DataFrame({\"id\": y_ids, \"is_tts\": y_probs})\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:25:05.954190Z","iopub.execute_input":"2025-03-10T17:25:05.954482Z","iopub.status.idle":"2025-03-10T17:25:44.961665Z","shell.execute_reply.started":"2025-03-10T17:25:05.954446Z","shell.execute_reply":"2025-03-10T17:25:44.960658Z"}},"outputs":[{"name":"stdout","text":"submission.csv saved successfully!\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:29:55.211761Z","iopub.execute_input":"2025-03-10T17:29:55.212061Z","iopub.status.idle":"2025-03-10T17:29:55.220043Z","shell.execute_reply.started":"2025-03-10T17:29:55.212038Z","shell.execute_reply":"2025-03-10T17:29:55.219245Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"                  id  is_tts\n0  ASM_F_ANGER_00109   0.841\n1  ASM_F_ANGER_00127   0.861\n2  ASM_F_ANGER_00386   0.704\n3  ASM_F_ANGER_00103   0.780\n4  ASM_F_ANGER_00434   0.521","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>is_tts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ASM_F_ANGER_00109</td>\n      <td>0.841</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ASM_F_ANGER_00127</td>\n      <td>0.861</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ASM_F_ANGER_00386</td>\n      <td>0.704</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ASM_F_ANGER_00103</td>\n      <td>0.780</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ASM_F_ANGER_00434</td>\n      <td>0.521</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"submission_df['is_tts'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:30:24.085633Z","iopub.execute_input":"2025-03-10T17:30:24.085995Z","iopub.status.idle":"2025-03-10T17:30:24.106604Z","shell.execute_reply.started":"2025-03-10T17:30:24.085966Z","shell.execute_reply":"2025-03-10T17:30:24.105786Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"is_tts\n0.493    52\n0.704    40\n0.941    16\n0.486    14\n0.489    13\n         ..\n0.444     1\n0.711     1\n0.348     1\n0.390     1\n0.655     1\nName: count, Length: 700, dtype: int64"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}