{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":95302,"databundleVersionId":11325230,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:03:42.447682Z","iopub.execute_input":"2025-03-10T06:03:42.447975Z","iopub.status.idle":"2025-03-10T06:03:43.593718Z","shell.execute_reply.started":"2025-03-10T06:03:42.447945Z","shell.execute_reply":"2025-03-10T06:03:43.592866Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/indic-tts-deepfake-challenge/sample.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Official dataset for this challenge\ndataset = load_dataset(\"SherryT997/IndicTTS-Deepfake-Challenge-Data\")  \n\n# Train and test splits\ntrain_data = dataset[\"train\"]  # Contains 'is_tts' labels\ntest_data = dataset[\"test\"]  # 'is_tts' is -1 for all rows\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:03:55.828421Z","iopub.execute_input":"2025-03-10T06:03:55.828724Z","iopub.status.idle":"2025-03-10T06:08:22.519257Z","shell.execute_reply.started":"2025-03-10T06:03:55.828703Z","shell.execute_reply":"2025-03-10T06:08:22.518370Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6babb3b1787b48ff9a723185fbdafd2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d4c607258ce476982c98b3f7fb1a866"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d088c088907422cae52c965759106c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/35 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff819e794384f17a12390336fb3e9ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00035.parquet:   0%|          | 0.00/453M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036eab7c8c004bf1bec892f85e6a78ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00035.parquet:   0%|          | 0.00/461M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f3f87ce579407c95789acc7a30b9d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00035.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5300b58a4cc499f95c29a465b63916c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00035.parquet:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a35faf201473437695a92f42786383da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00035.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edad7309d89a47b2b01b7f2c2d2e3255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00035.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11fa819ce284d8a8c6432febebde98f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00035.parquet:   0%|          | 0.00/447M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315609955dd846f78dcc10156048a341"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00035.parquet:   0%|          | 0.00/516M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac26257dcae84f3db40347dad8b31e18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00035.parquet:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1ea8fa49884125af640139f2adf09a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00035.parquet:   0%|          | 0.00/521M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c301747013f7442a818ea054fc7e5fe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00035.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01852ca68ca4cb4b7137728748ee48f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00035.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e89e19d2d1734ea985c328f2ecdfd840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00035.parquet:   0%|          | 0.00/414M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a573f953a0c24f59acb2286af2d99448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00035.parquet:   0%|          | 0.00/473M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a1cf9d93254431af83e0f76a427796"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00035.parquet:   0%|          | 0.00/481M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caa7e8cbad76417d9e953c9efec5524f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00035.parquet:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935d95dc05194592a58e3e9de97b1b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00035.parquet:   0%|          | 0.00/532M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd5a1f0cad164372949b1967a75868e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00035.parquet:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e89292f5c95440f28c81705ee1528e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00035.parquet:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bad16fad143457f80c05e0c1357de2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00035.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f34d4d50694cb9a81c43820dacc249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00035.parquet:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edd4a3a4632b43aeb2171b369f29c836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00035.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d129d99b0844ebdb65f9dde5c715a0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00035.parquet:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c1e2d5800e4a71afbf4629fa97f4d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00035.parquet:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ab402bb5c514ebd8e5db9c24791d811"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00035.parquet:   0%|          | 0.00/576M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb43b5ee78c8452f931d4798efd81e0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00035.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471709497f5647ef91ec1566104c2d24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00035.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6806fbd32c11495a8a2bf84bc00d6703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00035.parquet:   0%|          | 0.00/421M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f3c5e7b28a4191b609ce04304efd78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00035.parquet:   0%|          | 0.00/382M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6501e2c1847c4099acb0154e95ea0172"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00035.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f0309f918a24777af987422bce906d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00030-of-00035.parquet:   0%|          | 0.00/282M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5060742f16fa478ca256af40d5edfb07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00031-of-00035.parquet:   0%|          | 0.00/688M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b826f3379ddd48dcbe0174051fba03aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00032-of-00035.parquet:   0%|          | 0.00/613M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0694a12e3434077b0f29ddbfdd19480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00033-of-00035.parquet:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c8702837c54dd981cc1e3e2eb949df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00034-of-00035.parquet:   0%|          | 0.00/424M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5dfae725f14c79a672d4aa9a982a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00004.parquet:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"093459dd8f484e4c83e1920fbd05a433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00001-of-00004.parquet:   0%|          | 0.00/364M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c215f98330084bd8ba1c0548b1987999"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00002-of-00004.parquet:   0%|          | 0.00/410M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac124d7451fa448faddad26a25bd3402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00003-of-00004.parquet:   0%|          | 0.00/291M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"404d8324fc5c4b949dfa4be50f8a13fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/31102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ea239993bf74f4dbb981b2e583f810c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ba0b0adc4643ac96e94e9eff72db4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e09bf1c867f41ca89e2351301235e86"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train=train_data.shuffle()\n# train=train.shuffle()\n\nsubset=train.select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:11:48.939190Z","iopub.execute_input":"2025-03-10T06:11:48.939748Z","iopub.status.idle":"2025-03-10T06:11:48.990579Z","shell.execute_reply.started":"2025-03-10T06:11:48.939720Z","shell.execute_reply":"2025-03-10T06:11:48.989794Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# subset[:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:45.112272Z","iopub.execute_input":"2025-03-09T13:24:45.112597Z","iopub.status.idle":"2025-03-09T13:24:50.055251Z","shell.execute_reply.started":"2025-03-09T13:24:45.112565Z","shell.execute_reply":"2025-03-09T13:24:50.054242Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!pip install datasets transformers torchaudio librosa > /dev/null\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:11:51.732627Z","iopub.execute_input":"2025-03-10T06:11:51.732957Z","iopub.status.idle":"2025-03-10T06:11:57.176095Z","shell.execute_reply.started":"2025-03-10T06:11:51.732933Z","shell.execute_reply":"2025-03-10T06:11:57.174840Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torchaudio\nfrom transformers import Wav2Vec2Processor, Wav2Vec2Model\nimport os\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:13:13.174373Z","iopub.execute_input":"2025-03-10T06:13:13.174734Z","iopub.status.idle":"2025-03-10T06:13:35.883962Z","shell.execute_reply.started":"2025-03-10T06:13:13.174705Z","shell.execute_reply":"2025-03-10T06:13:35.883378Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab46b377b3a14b9fbb586bfb3fb886d6"}},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Extracting Embeddings:","metadata":{}},{"cell_type":"code","source":"# subset['audio'][:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:24:56.819510Z","iopub.execute_input":"2025-03-09T13:24:56.819733Z","iopub.status.idle":"2025-03-09T13:24:56.822943Z","shell.execute_reply.started":"2025-03-09T13:24:56.819716Z","shell.execute_reply":"2025-03-09T13:24:56.822328Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Extract audio arrays from subset\naudio_arrays = [item['array'] for item in subset['audio']]\n\n# Add the 'audio_array' column directly\ndataset_train = subset.add_column('audio_array', audio_arrays)\n\n# # Verify the new column\n# print(dataset_train[0]['audio_array'][:10])\n# print(dataset_train.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:14:37.991943Z","iopub.execute_input":"2025-03-10T06:14:37.992658Z","iopub.status.idle":"2025-03-10T06:15:07.471533Z","shell.execute_reply.started":"2025-03-10T06:14:37.992614Z","shell.execute_reply":"2025-03-10T06:15:07.470570Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e620f65f7c1640ff912bab8d3ccb6bee"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Extract audio arrays from subset\naudio_arrays = [item['array'] for item in test_data['audio']]\n\n# Add the 'audio_array' column directly\ndataset_test = test_data.add_column('audio_array', audio_arrays)\n\n# # Verify the new column\n# print(dataset_train[0]['audio_array'][:10])\n# print(dataset_train.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:15:46.477582Z","iopub.execute_input":"2025-03-10T06:15:46.477931Z","iopub.status.idle":"2025-03-10T06:16:13.949350Z","shell.execute_reply.started":"2025-03-10T06:15:46.477908Z","shell.execute_reply":"2025-03-10T06:16:13.948618Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset_train,dataset_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:16:26.816123Z","iopub.execute_input":"2025-03-10T06:16:26.816457Z","iopub.status.idle":"2025-03-10T06:16:26.821927Z","shell.execute_reply.started":"2025-03-10T06:16:26.816431Z","shell.execute_reply":"2025-03-10T06:16:26.821175Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_array'],\n     num_rows: 1000\n }),\n Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_array'],\n     num_rows: 2635\n }))"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\nfrom transformers import Wav2Vec2Processor, Wav2Vec2Model, HubertModel\nfrom datasets import Dataset  # Assuming dataset is a Hugging Face Dataset\n\n# Load the Wav2Vec 2.0 model and processor\n# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n# model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\nmodel = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n\n# Function to extract embeddings from audio data\ndef extract_embeddings(example):\n    audio_array = example['audio']['array']  # Extract audio array\n    sample_rate = example['audio']['sampling_rate']\n\n    # Resample if the sampling rate is not 16kHz\n    if sample_rate != 16000:\n        audio_array = torchaudio.transforms.Resample(sample_rate, 16000)(torch.tensor(audio_array))\n\n    # Process the waveform for the model\n    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n\n    # Extract embeddings\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Extract the last hidden state as embeddings (or pool if needed)\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n\n    # Add embeddings to the dataset\n    example['audio_embeddings'] = embeddings\n    return example\n\n\n# Map the embedding extraction function\ndataset_train = subset.map(extract_embeddings)\n\n# Check output\n# print(dataset[0]['audio_embeddings'].shape)  # Expected output: (768,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:59:57.850980Z","iopub.execute_input":"2025-03-10T07:59:57.851290Z","iopub.status.idle":"2025-03-10T08:28:27.390923Z","shell.execute_reply.started":"2025-03-10T07:59:57.851269Z","shell.execute_reply":"2025-03-10T08:28:27.389633Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aff594fd5a34af188026886812b286a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba24c80fb6cb4daeb04f381ba37f1b03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb5e89a9a144c42b09304660ea75f27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b5328646085422d963d0e82c84e8f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab52cbb11f148f8825d4f98f7a63eb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"739a077207494d7bb49e5c9146bb925b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15eb21fc03c145fdb3a7054a9b5ed9dd"}},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"# dataset_train['audio_embeddings'][:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T02:42:14.517469Z","iopub.execute_input":"2025-03-09T02:42:14.517843Z","iopub.status.idle":"2025-03-09T02:42:14.969300Z","shell.execute_reply.started":"2025-03-09T02:42:14.517815Z","shell.execute_reply":"2025-03-09T02:42:14.968243Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[[-0.044041793793439865,\n  0.012884334661066532,\n  -0.015163351781666279,\n  -0.02633092738687992,\n  0.0851236879825592,\n  -0.06182975322008133,\n  0.061708856374025345,\n  -0.03552279993891716,\n  0.026822388172149658,\n  -0.2951536476612091,\n  -0.043685927987098694,\n  -0.01577705703675747,\n  0.03703310340642929,\n  0.040204375982284546,\n  -0.18982668220996857,\n  0.01588919386267662,\n  -0.28721973299980164,\n  0.34316495060920715,\n  0.01779666170477867,\n  0.06850619614124298,\n  -0.19890627264976501,\n  0.07195549458265305,\n  0.06802411377429962,\n  0.018082400783896446,\n  0.21441401541233063,\n  -0.014859815128147602,\n  -0.262512743473053,\n  -0.005623433273285627,\n  -0.007746524177491665,\n  -0.10318316519260406,\n  0.13156624138355255,\n  -0.01049379725009203,\n  -0.11909525096416473,\n  -0.06912849843502045,\n  -0.1711677461862564,\n  -0.07443375140428543,\n  -0.02493377961218357,\n  -0.2574174404144287,\n  -0.10336143523454666,\n  -0.026921767741441727,\n  -0.165060356259346,\n  0.002119589364156127,\n  -0.15748248994350433,\n  0.153670996427536,\n  -0.13205385208129883,\n  0.192123681306839,\n  -0.04110676050186157,\n  -0.026866616681218147,\n  0.04058869928121567,\n  0.027587687596678734,\n  -0.1101607158780098,\n  -0.03298523649573326,\n  0.030093228444457054,\n  0.02677995339035988,\n  0.0044660428538918495,\n  0.002453682478517294,\n  0.011650261469185352,\n  -0.4320557713508606,\n  -0.15764766931533813,\n  -0.14131306111812592,\n  -0.02293204888701439,\n  -0.11316143721342087,\n  0.020401859655976295,\n  0.1620924472808838,\n  -0.025387512519955635,\n  0.10453552007675171,\n  -0.009647410362958908,\n  -0.12301529198884964,\n  -0.14460839331150055,\n  -0.03087998740375042,\n  -0.09429889172315598,\n  -0.030897153541445732,\n  -0.08553845435380936,\n  -0.06394124031066895,\n  0.035942476242780685,\n  0.029090246185660362,\n  0.04716035723686218,\n  0.04511285200715065,\n  -0.02340579777956009,\n  -0.0666920393705368,\n  -0.09464721381664276,\n  0.2835168242454529,\n  0.037605296820402145,\n  0.062177207320928574,\n  -0.024505360051989555,\n  0.07651372998952866,\n  -0.08199843764305115,\n  -0.18021634221076965,\n  -0.015766562893986702,\n  0.029357248917222023,\n  0.22141602635383606,\n  -0.0962432399392128,\n  0.10173820704221725,\n  0.02429940551519394,\n  0.04149588197469711,\n  -0.02820834144949913,\n  0.07589277625083923,\n  0.03909013047814369,\n  -0.031843800097703934,\n  -0.07941491156816483,\n  -0.010627920739352703,\n  -0.16917282342910767,\n  0.005199537146836519,\n  -0.18471543490886688,\n  0.1313999742269516,\n  0.2690185606479645,\n  -0.0297684445977211,\n  0.15655744075775146,\n  0.01347431167960167,\n  0.07609381526708603,\n  -0.024715261533856392,\n  -0.03678971529006958,\n  -0.06554921716451645,\n  0.013516760431230068,\n  -0.0884627178311348,\n  0.003340846160426736,\n  0.04752131924033165,\n  -0.025982212275266647,\n  -0.04584300145506859,\n  -0.15691804885864258,\n  0.057090044021606445,\n  0.003888025414198637,\n  0.0936034694314003,\n  0.006759887561202049,\n  -0.04816238209605217,\n  -0.19947880506515503,\n  0.05621647834777832,\n  0.31245288252830505,\n  -0.08957429230213165,\n  0.11062272638082504,\n  -0.003949716687202454,\n  -0.06695147603750229,\n  -0.08781491965055466,\n  -0.01928335800766945,\n  -0.07157924771308899,\n  -0.03341851010918617,\n  -0.08239129185676575,\n  -0.008810740895569324,\n  -0.015476389788091183,\n  -0.4297753870487213,\n  0.007527146954089403,\n  0.0690392479300499,\n  -0.015437697060406208,\n  0.3110445439815521,\n  0.022849198430776596,\n  0.003335535293444991,\n  -0.6207767724990845,\n  0.10515519231557846,\n  -0.23178748786449432,\n  0.08127692341804504,\n  0.01049890648573637,\n  0.14218252897262573,\n  0.09668982774019241,\n  -0.1173713356256485,\n  0.05099155381321907,\n  0.005074435845017433,\n  -0.0037695413921028376,\n  -0.005130311939865351,\n  0.274164617061615,\n  -0.07085681706666946,\n  -0.13829059898853302,\n  0.22967860102653503,\n  0.14380168914794922,\n  -0.010458881966769695,\n  0.039197828620672226,\n  -0.03635686635971069,\n  -0.05553833022713661,\n  -0.12493353337049484,\n  0.33943381905555725,\n  0.14837172627449036,\n  0.04055624455213547,\n  -0.09378678351640701,\n  0.048813022673130035,\n  0.24112877249717712,\n  -0.005223051644861698,\n  -0.2013818919658661,\n  -0.06641434133052826,\n  0.024216139689087868,\n  -0.0527561753988266,\n  0.00753498449921608,\n  -0.02414369396865368,\n  -0.010311124846339226,\n  -0.0018921408336609602,\n  -0.23609228432178497,\n  -0.10896699875593185,\n  -0.03584987297654152,\n  -0.04922915995121002,\n  -0.312338262796402,\n  -0.10077332705259323,\n  0.13558442890644073,\n  -0.07066494971513748,\n  -0.039921488612890244,\n  -0.06397747248411179,\n  -0.01069930661469698,\n  -0.03212335705757141,\n  0.08598480373620987,\n  -0.13654853403568268,\n  0.24497762322425842,\n  -0.08465080708265305,\n  -0.058637671172618866,\n  0.020867619663476944,\n  0.015047895722091198,\n  -0.2779436409473419,\n  0.14675569534301758,\n  -0.13283410668373108,\n  0.1393977850675583,\n  0.009648695588111877,\n  -0.0516679584980011,\n  0.06604369729757309,\n  0.24507369101047516,\n  -0.4780069887638092,\n  0.07542775571346283,\n  -0.006510363891720772,\n  0.014925936236977577,\n  0.029506342485547066,\n  -0.08576350659132004,\n  0.05071618780493736,\n  -0.15788961946964264,\n  -0.028137758374214172,\n  0.05584230273962021,\n  -0.10246957838535309,\n  -0.031423501670360565,\n  -0.19093602895736694,\n  0.005979034584015608,\n  -0.08937046676874161,\n  0.08488410711288452,\n  -0.005422081332653761,\n  0.22019915282726288,\n  -0.10284659266471863,\n  0.07471976429224014,\n  0.14998792111873627,\n  -0.03576669096946716,\n  0.041076093912124634,\n  -0.004727677442133427,\n  -0.011531167663633823,\n  -0.010473729111254215,\n  -0.003062075935304165,\n  -0.002368490444496274,\n  -0.023715991526842117,\n  0.05777382850646973,\n  0.04938695207238197,\n  -0.2759154736995697,\n  0.007597635965794325,\n  -0.05651974305510521,\n  -0.17297028005123138,\n  0.020427417010068893,\n  -0.03527655825018883,\n  0.15787114202976227,\n  0.07565953582525253,\n  -0.13832974433898926,\n  -0.031047377735376358,\n  0.17043046653270721,\n  -0.020465882495045662,\n  0.026342658326029778,\n  -0.0042574782855808735,\n  0.08917500823736191,\n  -0.32322072982788086,\n  0.03914991021156311,\n  0.049015939235687256,\n  -0.10729210823774338,\n  0.03889874741435051,\n  0.03862447291612625,\n  -0.03082260675728321,\n  0.007333050947636366,\n  -0.3011787533760071,\n  0.10447440296411514,\n  -0.031488463282585144,\n  -0.06383942812681198,\n  -0.03873497620224953,\n  -0.3234107792377472,\n  0.00912072416394949,\n  0.18775340914726257,\n  -0.0239675585180521,\n  0.01611490361392498,\n  -0.07632095366716385,\n  -0.048200398683547974,\n  0.006911206524819136,\n  0.018116673454642296,\n  -0.07414975017309189,\n  0.24413961172103882,\n  -0.06900918483734131,\n  0.08615517616271973,\n  0.09347642958164215,\n  0.12321927398443222,\n  0.09722242504358292,\n  -0.1604766696691513,\n  0.04722120612859726,\n  0.010971685871481895,\n  -0.280223548412323,\n  0.17011362314224243,\n  -0.28260424733161926,\n  -0.1424885392189026,\n  -0.008311484940350056,\n  0.1257639080286026,\n  0.0763283222913742,\n  0.013646703213453293,\n  -0.0011771132703870535,\n  -0.004503345116972923,\n  -0.02854912541806698,\n  0.007557817734777927,\n  -0.024594826623797417,\n  -0.29378435015678406,\n  -0.16020478308200836,\n  0.03953518345952034,\n  0.12535084784030914,\n  -0.03475114703178406,\n  0.21489931643009186,\n  0.005640477407723665,\n  0.030687907710671425,\n  -0.2382674366235733,\n  0.1813691109418869,\n  -0.12370967119932175,\n  -0.007505051791667938,\n  0.24353289604187012,\n  0.1336391270160675,\n  -0.10651285201311111,\n  -0.07059162855148315,\n  -0.12635552883148193,\n  -0.05202184244990349,\n  0.08270379900932312,\n  -0.027409082278609276,\n  0.14471732079982758,\n  0.03512755408883095,\n  -0.003214897122234106,\n  0.008993780240416527,\n  -0.0244668647646904,\n  -0.10831718146800995,\n  0.033716414123773575,\n  0.04427638277411461,\n  -0.06446999311447144,\n  -0.04496452957391739,\n  -0.037421319633722305,\n  0.058811064809560776,\n  0.07326900213956833,\n  0.08534500747919083,\n  0.0599215030670166,\n  0.03575639799237251,\n  0.03260117769241333,\n  -0.04134087637066841,\n  -0.028613753616809845,\n  -0.16919675469398499,\n  0.10275418311357498,\n  -0.07816268503665924,\n  -0.05702567100524902,\n  0.12286335974931717,\n  -0.01871841587126255,\n  0.09722917526960373,\n  0.08227455615997314,\n  0.5109602212905884,\n  0.002772678853943944,\n  -0.16614528000354767,\n  -0.004863624460995197,\n  0.6654949188232422,\n  0.028638040646910667,\n  0.08009696751832962,\n  -0.11663080006837845,\n  0.015635935589671135,\n  -0.15309008955955505,\n  -0.035404983907938004,\n  -0.20069757103919983,\n  0.12879276275634766,\n  -0.030786026269197464,\n  -0.14113599061965942,\n  0.032279692590236664,\n  0.009613781236112118,\n  -1.2008345127105713,\n  0.03516306355595589,\n  0.0821518525481224,\n  0.09321863949298859,\n  -0.0038569988682866096,\n  -0.0536789707839489,\n  0.09828221797943115,\n  -0.02035222016274929,\n  0.04638248309493065,\n  0.2042870819568634,\n  0.542323112487793,\n  0.13531708717346191,\n  0.01298174262046814,\n  0.09227030724287033,\n  -0.1060345396399498,\n  -0.020722011104226112,\n  0.13738375902175903,\n  0.0853661373257637,\n  0.17063115537166595,\n  0.07701125741004944,\n  -0.040661972016096115,\n  -0.5219548940658569,\n  -0.08851370960474014,\n  0.03401524946093559,\n  0.0483589731156826,\n  -0.20465964078903198,\n  -0.03486023470759392,\n  0.13154156506061554,\n  0.5177139639854431,\n  -0.05972487851977348,\n  0.48390987515449524,\n  -0.06296516954898834,\n  0.21932372450828552,\n  0.06854142248630524,\n  0.020755518227815628,\n  -0.16412176191806793,\n  -0.23846712708473206,\n  0.05885384604334831,\n  0.04638566076755524,\n  0.0005140664870850742,\n  0.09267666935920715,\n  -0.05324641242623329,\n  0.08071522414684296,\n  0.07783183455467224,\n  -0.07001534849405289,\n  0.04776298627257347,\n  -0.06918460130691528,\n  -0.08114199340343475,\n  0.0035450360737740993,\n  -0.1481003612279892,\n  -0.014884350821375847,\n  0.2622561752796173,\n  0.04075797274708748,\n  -0.026880810037255287,\n  0.02988407574594021,\n  -0.017945386469364166,\n  0.03970895707607269,\n  0.09096984565258026,\n  0.14597749710083008,\n  0.02223227173089981,\n  -0.05049072951078415,\n  -0.07787881791591644,\n  -0.06273681670427322,\n  -0.00219557317905128,\n  -0.0043041459284722805,\n  0.026719603687524796,\n  0.0482567623257637,\n  0.5127128958702087,\n  0.07198896259069443,\n  -0.20667845010757446,\n  -0.09727619588375092,\n  -0.20184697210788727,\n  -0.03638001158833504,\n  0.15805290639400482,\n  0.15930920839309692,\n  -0.09257636219263077,\n  -0.1142825037240982,\n  -0.042244795709848404,\n  0.013052521273493767,\n  0.004834538325667381,\n  0.47538602352142334,\n  -0.20517946779727936,\n  -0.025121144950389862,\n  -0.027956636622548103,\n  -0.268799364566803,\n  0.032643940299749374,\n  0.08565749228000641,\n  -0.5102023482322693,\n  -0.012699945829808712,\n  0.005542519502341747,\n  -0.038348305970430374,\n  -0.22731518745422363,\n  -0.036665432155132294,\n  0.1426910012960434,\n  0.06097598373889923,\n  0.04562784731388092,\n  0.032868798822164536,\n  -0.033407486975193024,\n  -0.10637576878070831,\n  -0.05266011506319046,\n  -0.47399571537971497,\n  0.0403263121843338,\n  -0.06987228989601135,\n  0.030851997435092926,\n  0.1432642787694931,\n  -0.04985206946730614,\n  0.10069818049669266,\n  -0.05220986157655716,\n  -0.14757628738880157,\n  0.08173274993896484,\n  -0.002374690491706133,\n  0.29425951838493347,\n  0.06953155994415283,\n  0.0009733069455251098,\n  0.0202502254396677,\n  0.0813550055027008,\n  -0.3868407607078552,\n  0.07465069741010666,\n  0.04082806780934334,\n  0.25093820691108704,\n  -0.14609910547733307,\n  0.07479247450828552,\n  0.06810341030359268,\n  0.020887821912765503,\n  -0.0834665298461914,\n  0.024668248370289803,\n  -0.07083910703659058,\n  -0.0010841682087630033,\n  -0.01913909986615181,\n  0.08969731628894806,\n  -0.085547536611557,\n  -0.011757786385715008,\n  -0.0987459346652031,\n  -0.04417688399553299,\n  0.018805906176567078,\n  -0.04281844198703766,\n  0.0180769432336092,\n  0.07513993233442307,\n  0.17238804697990417,\n  -0.1622282713651657,\n  -0.03603704646229744,\n  -0.0633743405342102,\n  -0.2436802089214325,\n  -0.023449866101145744,\n  -0.05274614691734314,\n  0.07040050625801086,\n  -0.17302092909812927,\n  -0.11377774178981781,\n  0.12720629572868347,\n  -0.07583607733249664,\n  0.05088596045970917,\n  -0.0155176417902112,\n  0.013178910128772259,\n  -0.058048758655786514,\n  -0.028079332783818245,\n  0.016616810113191605,\n  0.004188932478427887,\n  0.2617841064929962,\n  -0.026896078139543533,\n  0.039824437350034714,\n  0.05159103870391846,\n  -0.4652523100376129,\n  -0.05751095712184906,\n  -0.1709182858467102,\n  0.03368359059095383,\n  0.09543269872665405,\n  0.18091098964214325,\n  -0.032310258597135544,\n  0.04003756865859032,\n  0.37216076254844666,\n  -0.006433289032429457,\n  -0.06630854308605194,\n  0.023503119125962257,\n  0.1437048763036728,\n  0.02568744122982025,\n  -0.30483806133270264,\n  0.0023122967686504126,\n  0.09953296929597855,\n  -0.1531481146812439,\n  0.21195726096630096,\n  0.05270301178097725,\n  0.09482026100158691,\n  0.42356443405151367,\n  -0.1428263783454895,\n  -0.03790956735610962,\n  0.01826825924217701,\n  -0.03825603052973747,\n  0.08655840158462524,\n  -0.008518056012690067,\n  -0.007623118814080954,\n  -0.26737403869628906,\n  -0.10958611220121384,\n  0.017032161355018616,\n  -0.05841181054711342,\n  0.3412078619003296,\n  -0.008091086521744728,\n  -0.058209557086229324,\n  -0.02445027604699135,\n  -0.027108797803521156,\n  -0.06031143665313721,\n  0.04808369278907776,\n  0.01690227910876274,\n  -0.11282456666231155,\n  -8.57377585816721e-07,\n  0.11876450479030609,\n  0.05591926723718643,\n  0.001173780532553792,\n  0.02684829942882061,\n  0.017663054168224335,\n  0.14299078285694122,\n  0.0756470113992691,\n  -0.03688295558094978,\n  0.17345698177814484,\n  0.26524773240089417,\n  0.006837673485279083,\n  -0.01157077495008707,\n  0.17763926088809967,\n  -0.15917232632637024,\n  -0.03704318404197693,\n  -0.04807180538773537,\n  -0.16546611487865448,\n  -0.10835471749305725,\n  0.1558912694454193,\n  0.10637304186820984,\n  -0.012083514593541622,\n  -0.020228328183293343,\n  0.19372037053108215,\n  -0.07900340110063553,\n  -0.0648702085018158,\n  0.15590260922908783,\n  0.05483821779489517,\n  -0.0021495188120752573,\n  0.025196334347128868,\n  0.025368686765432358,\n  0.09952904284000397,\n  0.030190182849764824,\n  0.07979335635900497,\n  -0.0020557900425046682,\n  -0.26858487725257874,\n  -0.3383607864379883,\n  0.025639409199357033,\n  -0.0313357338309288,\n  0.08335962146520615,\n  0.001142833149060607,\n  -0.0017040650127455592,\n  0.2614205777645111,\n  -0.08481540530920029,\n  -0.035743821412324905,\n  0.12557967007160187,\n  0.09244253486394882,\n  -0.1709032505750656,\n  0.1446399986743927,\n  0.0202887374907732,\n  -0.31398433446884155,\n  -0.3206214904785156,\n  -0.07816877216100693,\n  -0.006348433904349804,\n  0.03302041441202164,\n  0.10403288155794144,\n  -0.06874700635671616,\n  0.04126407206058502,\n  0.2596248686313629,\n  -0.09631247818470001,\n  -0.19114406406879425,\n  0.022670719772577286,\n  0.009582653641700745,\n  0.04066181927919388,\n  0.2884695529937744,\n  -0.046454545110464096,\n  -0.005812113638967276,\n  -0.00867356639355421,\n  0.051563821732997894,\n  0.06215030327439308,\n  0.10725037008523941,\n  -0.02436918579041958,\n  0.019858343526721,\n  0.058240555226802826,\n  -0.02388690412044525,\n  0.013978424482047558,\n  -0.07402929663658142,\n  0.19432342052459717,\n  -0.04824097082018852,\n  -0.11498317867517471,\n  -0.03607824817299843,\n  0.03401092812418938,\n  0.019148191437125206,\n  -0.17086687684059143,\n  -0.06787795573472977,\n  -0.07013054192066193,\n  -0.013705347664654255,\n  0.020678941160440445,\n  -0.22655662894248962,\n  -0.016418425366282463,\n  -0.11876160651445389,\n  0.00898120179772377,\n  0.12178824841976166,\n  -0.025057772174477577,\n  0.0075000012293457985,\n  -0.27187418937683105,\n  -0.09782305359840393,\n  0.004141749814152718,\n  0.08218331634998322,\n  -0.12138625979423523,\n  -0.06960423290729523,\n  0.052922286093235016,\n  -0.0049735987558960915,\n  0.05999996140599251,\n  0.008053092285990715,\n  0.016780385747551918,\n  -0.01790335588157177,\n  -0.002650306560099125,\n  0.004987497813999653,\n  0.02601306326687336,\n  0.028632933273911476,\n  0.025792697444558144,\n  -0.06511518359184265,\n  0.028560159727931023,\n  -0.13531219959259033,\n  -0.1348566859960556,\n  -0.09390702098608017,\n  0.5186141729354858,\n  0.33782759308815,\n  0.14122961461544037,\n  -0.3596705496311188,\n  0.24619324505329132,\n  -0.1362927109003067,\n  0.09790070354938507,\n  -0.00586475757881999,\n  -0.028975998982787132,\n  0.015525122173130512,\n  0.22567413747310638,\n  0.09186634421348572,\n  -0.06865072250366211,\n  0.1562604457139969,\n  0.0642654299736023,\n  0.18687979876995087,\n  0.007322285789996386,\n  0.22204595804214478,\n  0.07657438516616821,\n  0.0962369292974472,\n  0.043028153479099274,\n  0.030596263706684113,\n  -0.06790510565042496,\n  -0.022509507834911346,\n  0.12194481492042542,\n  -0.018140260130167007,\n  -0.00839230790734291,\n  -0.03069666214287281,\n  0.18410111963748932,\n  -0.189325749874115,\n  0.35362935066223145,\n  0.05824006721377373,\n  0.3049911558628082,\n  0.15127167105674744,\n  -0.16526898741722107,\n  0.10746148973703384,\n  0.044521741569042206,\n  0.007910452783107758,\n  -0.07297356426715851,\n  0.09447828680276871,\n  -0.05689693242311478,\n  0.09308499097824097,\n  0.019218122586607933,\n  0.001415063627064228,\n  -0.010416638106107712,\n  0.2013883739709854,\n  -0.06451427191495895,\n  -0.4919026792049408,\n  -0.06556989997625351,\n  0.19745942950248718,\n  0.07186702638864517,\n  0.1206963062286377,\n  -0.21303556859493256,\n  -0.012362176552414894,\n  -0.26898887753486633,\n  -0.007966048084199429,\n  -0.18515650928020477,\n  -0.11385807394981384,\n  0.04660505801439285,\n  -0.13621655106544495,\n  -0.04090964049100876,\n  -0.03184421733021736,\n  0.10773870348930359,\n  -0.05608852207660675,\n  -0.022791322320699692,\n  -0.026454096660017967,\n  0.05261227861046791,\n  0.012799503281712532,\n  -0.0841970220208168,\n  -0.016675865277647972,\n  0.05786152556538582,\n  0.0026899524964392185,\n  0.05744492635130882,\n  0.22099408507347107,\n  -0.05125311389565468,\n  0.061493657529354095,\n  0.05053730681538582,\n  -0.14406511187553406,\n  0.011219088919460773,\n  -0.02072140760719776,\n  -0.10905696451663971,\n  0.003375554922968149,\n  -0.11442174017429352]]"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"### Repeating the same for test dataset","metadata":{}},{"cell_type":"code","source":"# Load the Wav2Vec 2.0 model and processor\n# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n# model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\nmodel = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n\n# Function to extract embeddings from audio data\ndef extract_embeddings(example):\n    audio_array = example['audio']['array']  # Extract audio array\n    sample_rate = example['audio']['sampling_rate']\n\n    # Resample if the sampling rate is not 16kHz\n    if sample_rate != 16000:\n        audio_array = torchaudio.transforms.Resample(sample_rate, 16000)(torch.tensor(audio_array))\n\n    # Process the waveform for the model\n    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n\n    # Extract embeddings\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Extract the last hidden state as embeddings (or pool if needed)\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n\n    # Add embeddings to the dataset\n    example['audio_embeddings'] = embeddings\n    return example\n\n\n# Map the embedding extraction function\ndataset_test = test_data.map(extract_embeddings)\n\n# Check output\n# print(dataset[0]['audio_embeddings'].shape)  # Expected output: (768,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:29:57.831311Z","iopub.execute_input":"2025-03-10T08:29:57.831708Z","iopub.status.idle":"2025-03-10T09:45:18.233325Z","shell.execute_reply.started":"2025-03-10T08:29:57.831679Z","shell.execute_reply":"2025-03-10T09:45:18.232291Z"}},"outputs":[{"name":"stderr","text":"Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d113910e064a4f6aa5436888202d43ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e9cf93907a49c3977b12cf4791329f"}},"metadata":{}}],"execution_count":100},{"cell_type":"markdown","source":"### Adding the column Array(Audio)","metadata":{}},{"cell_type":"code","source":"dataset_train,dataset_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:47:57.244457Z","iopub.execute_input":"2025-03-10T09:47:57.244891Z","iopub.status.idle":"2025-03-10T09:47:57.251013Z","shell.execute_reply.started":"2025-03-10T09:47:57.244853Z","shell.execute_reply":"2025-03-10T09:47:57.250124Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_embeddings'],\n     num_rows: 1000\n }),\n Dataset({\n     features: ['text', 'id', 'language', 'is_tts', 'audio', 'audio_embeddings'],\n     num_rows: 2635\n }))"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"train_ = dataset_train\ntest_= dataset_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:47:59.718764Z","iopub.execute_input":"2025-03-10T09:47:59.719108Z","iopub.status.idle":"2025-03-10T09:47:59.745732Z","shell.execute_reply.started":"2025-03-10T09:47:59.719083Z","shell.execute_reply":"2025-03-10T09:47:59.744734Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"import librosa\nimport numpy as np\nimport torch\n\n# Parameters for feature extraction\nSR = 16000     # Target sampling rate\nN_MFCC = 13    # Number of MFCC features\nN_MELS = 128   # Number of Mel bands\nN_FFT = 1024   # FFT window size\nHOP_LENGTH = 512  # Hop size for overlapping segments\n\n# Combined feature extraction function\ndef extract_audio_features(batch):\n    audio_data = batch['audio']['array']\n    sampling_rate = batch['audio']['sampling_rate']\n\n    # Resample to target sampling rate\n    if sampling_rate != SR:\n        audio_data = librosa.resample(audio_data, orig_sr=sampling_rate, target_sr=SR)\n    \n    # MFCC Features\n    mfcc_features = librosa.feature.mfcc(y=audio_data, sr=SR, n_mfcc=N_MFCC)\n\n    # Mel-spectrogram\n    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)  # Convert to decibel scale\n\n    # Chroma Features\n    chroma_features = librosa.feature.chroma_stft(y=audio_data, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH)\n\n    # Spectrogram\n    spectrogram = np.abs(librosa.stft(audio_data, n_fft=N_FFT, hop_length=HOP_LENGTH))\n\n    # Flatten and combine features\n    combined_features = np.concatenate([\n        mfcc_features.T,               # Shape: (Time, N_MFCC)\n        mel_spectrogram_db.T,          # Shape: (Time, N_MELS)\n        chroma_features.T,             # Shape: (Time, 12)\n        spectrogram.T                  # Shape: (Time, Freq Bins)\n    ], axis=1)                         # Combined shape: (Time, Total Features)\n\n    # Convert to PyTorch tensor\n    batch['combined_features'] = torch.tensor(combined_features, dtype=torch.float32)\n    \n    return batch\n\n# Apply the function to your dataset\ntest_ = test_.map(extract_audio_features, remove_columns=[\"audio\"])\ntrain_ = train_.map(extract_audio_features, remove_columns=[\"audio\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:48:05.113584Z","iopub.execute_input":"2025-03-10T09:48:05.113941Z","iopub.status.idle":"2025-03-10T09:50:44.581056Z","shell.execute_reply.started":"2025-03-10T09:48:05.113913Z","shell.execute_reply":"2025-03-10T09:50:44.579897Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a148064fc50d4cd6b7dfa718882ae203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ad3aa301534bc2b31c8e4679641c90"}},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"Y = train_['is_tts']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:52:16.630377Z","iopub.execute_input":"2025-03-10T09:52:16.630859Z","iopub.status.idle":"2025-03-10T09:52:16.637657Z","shell.execute_reply.started":"2025-03-10T09:52:16.630815Z","shell.execute_reply":"2025-03-10T09:52:16.636153Z"}},"outputs":[],"execution_count":104},{"cell_type":"code","source":"test_= test_.remove_columns(['text', 'id', 'language','is_tts'])\ntrain_= train_.remove_columns(['text', 'id', 'language','is_tts'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:52:19.240158Z","iopub.execute_input":"2025-03-10T09:52:19.240457Z","iopub.status.idle":"2025-03-10T09:52:19.248869Z","shell.execute_reply.started":"2025-03-10T09:52:19.240435Z","shell.execute_reply":"2025-03-10T09:52:19.248164Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"test_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:52:21.519202Z","iopub.execute_input":"2025-03-10T09:52:21.519523Z","iopub.status.idle":"2025-03-10T09:52:21.525431Z","shell.execute_reply.started":"2025-03-10T09:52:21.519500Z","shell.execute_reply":"2025-03-10T09:52:21.524551Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['audio_embeddings', 'combined_features'],\n    num_rows: 2635\n})"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Extracting features and embeddings\ncombined_features = [np.mean(sample['combined_features'], axis=0) for sample in train_]  # Averaging across time steps\naudio_embeddings = [sample['audio_embeddings'] for sample in train_]\n\n# Creating DataFrame\ndf = pd.DataFrame({\n    'combined_features': combined_features,\n    'audio_embeddings': audio_embeddings\n})\n\n# Expanding nested arrays into separate columns for better usability\ncombined_features_df = pd.DataFrame(df['combined_features'].tolist(), columns=[f'feat_{i}' for i in range(len(combined_features[0]))])\naudio_embeddings_df = pd.DataFrame(df['audio_embeddings'].tolist(), columns=[f'emb_{i}' for i in range(len(audio_embeddings[0]))])\n\n# Final DataFrame combining both\nfinal_df = pd.concat([combined_features_df, audio_embeddings_df], axis=1)\n\nprint(final_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:52:24.262336Z","iopub.execute_input":"2025-03-10T09:52:24.262705Z","iopub.status.idle":"2025-03-10T09:54:21.958764Z","shell.execute_reply.started":"2025-03-10T09:52:24.262665Z","shell.execute_reply":"2025-03-10T09:54:21.957899Z"}},"outputs":[{"name":"stdout","text":"       feat_0     feat_1     feat_2     feat_3     feat_4     feat_5  \\\n0 -292.134625  79.321866   0.033918  30.744908  -6.143546  -4.639097   \n1 -315.719726  85.811098 -12.112796   2.160549 -12.029205 -14.868008   \n2 -299.873302  67.123330 -59.114664   4.253698 -19.440907 -24.253683   \n3 -335.450949  79.295036 -20.736728   4.662554 -15.642205 -20.654358   \n4 -310.352322  77.256998   3.065531  20.494106  -7.604571  -1.399842   \n\n      feat_6     feat_7     feat_8     feat_9  ...  emb_1014  emb_1015  \\\n0  -9.796030 -17.988524 -14.601004  -3.926365  ...  0.318144  0.314472   \n1  -6.154202 -22.299274  -8.183169 -17.452082  ...  0.329185  0.259316   \n2 -11.781221 -32.919796 -11.647967   1.954957  ...  0.331194  0.328642   \n3 -21.418426 -16.035885  -0.547264 -11.774237  ...  0.324698  0.255457   \n4  -2.943534  -6.435089 -14.098884   2.711456  ...  0.402772  0.280527   \n\n   emb_1016  emb_1017  emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  \\\n0 -0.083532 -0.033003 -0.318039 -0.493747  0.184293 -0.277759 -0.202203   \n1 -0.176832 -0.063490 -0.241320 -0.476742  0.078256 -0.300553 -0.137207   \n2 -0.133031 -0.085393 -0.341009 -0.460580  0.101227 -0.274854 -0.224809   \n3 -0.144440 -0.099939 -0.272775 -0.454404  0.075935 -0.285548 -0.187107   \n4 -0.124000 -0.061535 -0.212687 -0.510172  0.029389 -0.303155 -0.154668   \n\n   emb_1023  \n0  0.116947  \n1  0.101362  \n2  0.117281  \n3  0.089153  \n4  0.122388  \n\n[5 rows x 1690 columns]\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Extracting features and embeddings\ncombined_features = [np.mean(sample['combined_features'], axis=0) for sample in test_]  # Averaging across time steps\naudio_embeddings = [sample['audio_embeddings'] for sample in test_]\n\n# Creating DataFrame\ndf = pd.DataFrame({\n    'combined_features': combined_features,\n    'audio_embeddings': audio_embeddings\n})\n\n# Expanding nested arrays into separate columns for better usability\ncombined_features_df = pd.DataFrame(df['combined_features'].tolist(), columns=[f'feat_{i}' for i in range(len(combined_features[0]))])\naudio_embeddings_df = pd.DataFrame(df['audio_embeddings'].tolist(), columns=[f'emb_{i}' for i in range(len(audio_embeddings[0]))])\n\n# Final DataFrame combining both\ntest_df = pd.concat([combined_features_df, audio_embeddings_df], axis=1)\n\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:55:15.155463Z","iopub.execute_input":"2025-03-10T09:55:15.155816Z","iopub.status.idle":"2025-03-10T10:00:20.696560Z","shell.execute_reply.started":"2025-03-10T09:55:15.155788Z","shell.execute_reply":"2025-03-10T10:00:20.695704Z"}},"outputs":[{"name":"stdout","text":"       feat_0     feat_1     feat_2     feat_3     feat_4    feat_5  \\\n0 -323.679991  76.520725 -12.137748  14.131280 -25.446220  4.976515   \n1 -345.252255  82.258486 -13.390476   9.848259 -23.343344  6.942505   \n2 -370.560773  59.250755 -19.189193  18.276547 -24.782527  5.977365   \n3 -349.805191  87.443112 -10.931218  19.521460 -16.039356  7.323803   \n4 -329.224893  68.345302  -5.554238  29.161562 -21.079068  4.911482   \n\n      feat_6     feat_7     feat_8    feat_9  ...  emb_1014  emb_1015  \\\n0 -14.923873  -9.487348 -15.419669 -1.593292  ...  0.351153  0.326279   \n1 -15.918027  -6.746600 -10.526957  1.653832  ...  0.340752  0.270363   \n2 -14.447390  -7.055883 -11.126095 -0.680792  ...  0.343377  0.201739   \n3 -15.130816 -10.561822 -13.100427  1.293102  ...  0.347815  0.249999   \n4 -14.557055 -15.596798 -16.979532 -2.232384  ...  0.364617  0.256813   \n\n   emb_1016  emb_1017  emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  \\\n0 -0.170942 -0.059725 -0.297279 -0.467009  0.081014 -0.303032 -0.186773   \n1 -0.136730 -0.092803 -0.228636 -0.503723  0.020395 -0.338074 -0.140802   \n2 -0.119455 -0.094932 -0.240846 -0.584142  0.118583 -0.267348 -0.201916   \n3 -0.180494 -0.087353 -0.198068 -0.414230  0.033941 -0.338087 -0.158482   \n4 -0.157493 -0.083005 -0.291374 -0.407580  0.032229 -0.327276 -0.153905   \n\n   emb_1023  \n0  0.109294  \n1  0.123943  \n2  0.145991  \n3  0.085211  \n4  0.172938  \n\n[5 rows x 1690 columns]\n","output_type":"stream"}],"execution_count":108},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit and transform the data\nscaled_features = scaler.fit_transform(final_df)\n# scaled_features_test = scaler.fit_transform(test_df)\n# Convert back to DataFrame for easier handling\nscaled_df = pd.DataFrame(scaled_features, columns=final_df.columns)\n\nprint(scaled_df.head())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-10T10:27:58.860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming 'scaler' was fitted on the training data\nscaled_test_features = scaler.transform(test_df)\n\n# Convert back to DataFrame for consistency\nscaled_test_df = pd.DataFrame(scaled_test_features, columns=test_df.columns)\n\nprint(scaled_test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:05:42.948778Z","iopub.execute_input":"2025-03-10T10:05:42.949078Z","iopub.status.idle":"2025-03-10T10:05:43.016868Z","shell.execute_reply.started":"2025-03-10T10:05:42.949058Z","shell.execute_reply":"2025-03-10T10:05:43.015846Z"}},"outputs":[{"name":"stdout","text":"     feat_0    feat_1    feat_2    feat_3    feat_4    feat_5    feat_6  \\\n0 -0.053936 -0.376629 -0.440488 -0.748104 -1.236694  1.079851 -0.742445   \n1 -0.424180 -0.043652 -0.523109 -1.084278 -1.051847  1.347072 -0.835876   \n2 -0.858550 -1.378849 -0.905549 -0.422743 -1.178354  1.215889 -0.697665   \n3 -0.502322  0.257225 -0.360915 -0.325030 -0.409810  1.398899 -0.761894   \n4 -0.149103 -0.851069 -0.006289  0.431621 -0.852812  1.071012 -0.707971   \n\n     feat_7    feat_8    feat_9  ...  emb_1014  emb_1015  emb_1016  emb_1017  \\\n0  0.786041 -1.187201  0.828540  ... -0.148909  1.509041 -0.838284  0.807584   \n1  1.131799 -0.549938  1.304685  ... -0.405730  0.694346  0.266913 -0.258514   \n2  1.092782 -0.627974  0.962345  ... -0.340911 -0.305518  0.824937 -0.327141   \n3  0.650491 -0.885126  1.251789  ... -0.231318  0.397639 -1.146847 -0.082877   \n4  0.015304 -1.390369  0.734826  ...  0.183532  0.496924 -0.403838  0.057271   \n\n   emb_1018  emb_1019  emb_1020  emb_1021  emb_1022  emb_1023  \n0 -0.704222  0.939113 -0.272222 -0.555918 -0.511662  0.189521  \n1  0.543188  0.492339 -0.991900 -1.180773  0.630356  0.647084  \n2  0.321308 -0.486279  0.173788  0.080376 -0.887838  1.335744  \n3  1.098682  1.581377 -0.831084 -1.181004  0.191137 -0.562710  \n4 -0.596917  1.662298 -0.851405 -0.988233  0.304842  2.177465  \n\n[5 rows x 1690 columns]\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"Y[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:05:46.315379Z","iopub.execute_input":"2025-03-10T10:05:46.315725Z","iopub.status.idle":"2025-03-10T10:05:46.320715Z","shell.execute_reply.started":"2025-03-10T10:05:46.315696Z","shell.execute_reply":"2025-03-10T10:05:46.320042Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\n# Initialize the XGBoost Classifier\nmodel = xgb.XGBClassifier(\n    objective='binary:logistic',\n    eval_metric='logloss',\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\n# Train the model on scaled data\nmodel.fit(scaled_df, Y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:05:58.732369Z","iopub.execute_input":"2025-03-10T10:05:58.732719Z","iopub.status.idle":"2025-03-10T10:06:11.964766Z","shell.execute_reply.started":"2025-03-10T10:05:58.732690Z","shell.execute_reply":"2025-03-10T10:06:11.963892Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nmodel_lgbm = LGBMClassifier(\n    objective='binary',\n    metric='binary_logloss',\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\nmodel_lgbm.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:06:11.966095Z","iopub.execute_input":"2025-03-10T10:06:11.966421Z","iopub.status.idle":"2025-03-10T10:06:23.893467Z","shell.execute_reply.started":"2025-03-10T10:06:11.966388Z","shell.execute_reply":"2025-03-10T10:06:23.892685Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 476, number of negative: 524\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079537 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 430950\n[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 1690\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476000 -> initscore=-0.096074\n[LightGBM] [Info] Start training from score -0.096074\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(max_depth=6, metric='binary_logloss', n_estimators=200,\n               objective='binary', random_state=42)","text/html":"<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=6, metric=&#x27;binary_logloss&#x27;, n_estimators=200,\n               objective=&#x27;binary&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=6, metric=&#x27;binary_logloss&#x27;, n_estimators=200,\n               objective=&#x27;binary&#x27;, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nmodel_gb = GradientBoostingClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)\nmodel_gb.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:06:23.894805Z","iopub.execute_input":"2025-03-10T10:06:23.895023Z","iopub.status.idle":"2025-03-10T10:09:07.491839Z","shell.execute_reply.started":"2025-03-10T10:06:23.895006Z","shell.execute_reply":"2025-03-10T10:09:07.490691Z"}},"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"GradientBoostingClassifier(max_depth=6, n_estimators=200, random_state=42)","text/html":"<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=6, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=6, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":115},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nmodel_ab = AdaBoostClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    random_state=42\n)\nmodel_ab.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:09:07.493308Z","iopub.execute_input":"2025-03-10T10:09:07.493541Z","iopub.status.idle":"2025-03-10T10:09:46.051594Z","shell.execute_reply.started":"2025-03-10T10:09:07.493521Z","shell.execute_reply":"2025-03-10T10:09:46.050627Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)","text/html":"<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create the RandomForest model\nmodel_rf = RandomForestClassifier(\n    n_estimators=200, \n    random_state=42    \n)\n\nmodel_rf.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:09:46.052573Z","iopub.execute_input":"2025-03-10T10:09:46.052913Z","iopub.status.idle":"2025-03-10T10:09:50.385085Z","shell.execute_reply.started":"2025-03-10T10:09:46.052879Z","shell.execute_reply":"2025-03-10T10:09:50.384350Z"}},"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(n_estimators=200, random_state=42)","text/html":"<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":117},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n# Create and train the CatBoost model\nmodel_cat = CatBoostClassifier(\n    iterations=200,\n    learning_rate=0.1,\n    depth=6,\n    random_state=42,\n    verbose=0  # Turn off verbose to suppress output\n)\n\nmodel_cat.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:09:50.385852Z","iopub.execute_input":"2025-03-10T10:09:50.386069Z","iopub.status.idle":"2025-03-10T10:10:27.465704Z","shell.execute_reply.started":"2025-03-10T10:09:50.386050Z","shell.execute_reply":"2025-03-10T10:10:27.464871Z"}},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x78033e7e4a00>"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"from sklearn.ensemble import HistGradientBoostingClassifier\n\n# Create and train the Histogram-based Gradient Boosting model\nmodel_hgb = HistGradientBoostingClassifier(\n    max_iter=200,\n    learning_rate=0.1,\n    random_state=42\n)\n\nmodel_hgb.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:27.466489Z","iopub.execute_input":"2025-03-10T10:10:27.466791Z","iopub.status.idle":"2025-03-10T10:10:45.474485Z","shell.execute_reply.started":"2025-03-10T10:10:27.466757Z","shell.execute_reply":"2025-03-10T10:10:45.473601Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"HistGradientBoostingClassifier(max_iter=200, random_state=42)","text/html":"<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier(max_iter=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_iter=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\n# Create and train MLP model\nmodel_mlp = MLPClassifier(\n    hidden_layer_sizes=(100, 50),  # Number of neurons in each layer\n    max_iter=1000,\n    random_state=42\n)\n\nmodel_mlp.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:45.476895Z","iopub.execute_input":"2025-03-10T10:10:45.477133Z","iopub.status.idle":"2025-03-10T10:10:47.339059Z","shell.execute_reply.started":"2025-03-10T10:10:45.477113Z","shell.execute_reply":"2025-03-10T10:10:47.338094Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)","text/html":"<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"# from lightgbm import LGBMClassifier\n\n# model_lgbm = LGBMClassifier(\n#     objective='binary',\n#     metric='binary_logloss',\n#     n_estimators=500,       # Increase number of estimators for more boosting rounds\n#     learning_rate=0.05,     # Lower the learning rate for better convergence\n#     max_depth=7,            # Increase max depth for deeper trees\n#     num_leaves=32,          # Increase number of leaves (higher capacity)\n#     subsample=0.8,          # Subsample ratio to avoid overfitting\n#     colsample_bytree=0.8,   # Column sample by tree (use 80% features per tree)\n#     min_child_samples=20,   # Minimum number of samples per leaf\n#     random_state=42\n# )\n\n# model_lgbm.fit(scaled_df, Y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.340414Z","iopub.execute_input":"2025-03-10T10:10:47.340700Z","iopub.status.idle":"2025-03-10T10:10:47.344174Z","shell.execute_reply.started":"2025-03-10T10:10:47.340678Z","shell.execute_reply":"2025-03-10T10:10:47.343155Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"y_pred_proba = model_lgbm.predict_proba(scaled_test_df)[:, 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.345095Z","iopub.execute_input":"2025-03-10T10:10:47.345432Z","iopub.status.idle":"2025-03-10T10:10:47.408352Z","shell.execute_reply.started":"2025-03-10T10:10:47.345400Z","shell.execute_reply":"2025-03-10T10:10:47.407718Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"# round(y_pred_proba,3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.409068Z","iopub.execute_input":"2025-03-10T10:10:47.409285Z","iopub.status.idle":"2025-03-10T10:10:47.413058Z","shell.execute_reply.started":"2025-03-10T10:10:47.409266Z","shell.execute_reply":"2025-03-10T10:10:47.412280Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.413821Z","iopub.execute_input":"2025-03-10T10:10:47.414110Z","iopub.status.idle":"2025-03-10T10:10:47.430432Z","shell.execute_reply.started":"2025-03-10T10:10:47.414083Z","shell.execute_reply":"2025-03-10T10:10:47.429677Z"}},"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'id', 'language', 'is_tts', 'audio'],\n    num_rows: 2635\n})"},"metadata":{}}],"execution_count":124},{"cell_type":"code","source":"y_pred_proba[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.431347Z","iopub.execute_input":"2025-03-10T10:10:47.431627Z","iopub.status.idle":"2025-03-10T10:10:47.444039Z","shell.execute_reply.started":"2025-03-10T10:10:47.431600Z","shell.execute_reply":"2025-03-10T10:10:47.443348Z"}},"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"0.009266914078197548"},"metadata":{}}],"execution_count":125},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Ensure y_pred is 1D\n# y_pred_proba = np.ravel(y_pred)  # Flattens to 1D if it's 2D\n\n# Create DataFrame\nresults_df = pd.DataFrame({\n    'id': test_data['id'],  # Extract 'id' from test_data\n    'is_tts': y_pred_proba\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.444739Z","iopub.execute_input":"2025-03-10T10:10:47.444938Z","iopub.status.idle":"2025-03-10T10:10:47.463825Z","shell.execute_reply.started":"2025-03-10T10:10:47.444921Z","shell.execute_reply":"2025-03-10T10:10:47.463165Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"results_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.464615Z","iopub.execute_input":"2025-03-10T10:10:47.464922Z","iopub.status.idle":"2025-03-10T10:10:47.482472Z","shell.execute_reply.started":"2025-03-10T10:10:47.464890Z","shell.execute_reply":"2025-03-10T10:10:47.481712Z"}},"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"(2635, 2)"},"metadata":{}}],"execution_count":127},{"cell_type":"code","source":"results_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:10:47.483202Z","iopub.execute_input":"2025-03-10T10:10:47.483436Z","iopub.status.idle":"2025-03-10T10:10:47.504212Z","shell.execute_reply.started":"2025-03-10T10:10:47.483407Z","shell.execute_reply":"2025-03-10T10:10:47.503443Z"}},"outputs":[],"execution_count":128},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}