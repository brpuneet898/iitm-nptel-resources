{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GA5 DLP  "
      ],
      "metadata": {
        "id": "qrd0VI5nLW5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`This guide will walk you through creating the Python notebook for Week 6's assignment on speaker diarization and identification. You will be building a pipeline that transcribes audio, extracts speaker embeddings, clusters these embeddings to identify potential speakers, and then attempts to label these speakers by comparing them to known speaker profiles.`"
      ],
      "metadata": {
        "id": "mzelKJ07LjOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Install necessary libraries\n",
        "\n",
        "Note: Use correct versions  "
      ],
      "metadata": {
        "id": "WZarULDeSVK2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6BPgbHOLLT4u",
        "outputId": "69a1c227-0d7a-44ca-d322-bd3e2e81861a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speechbrain==0.5.16 in /usr/local/lib/python3.11/dist-packages (0.5.16)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.16) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.16) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.16) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain==0.5.16) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.16) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.16) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (2025.1.31)\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.28.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.0)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (1.20.1)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (14.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: pyannote.audio in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.28.1)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.5.0.post0)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (5.1.3)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.8.1)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.0.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote.audio)\n",
            "  Using cached speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.2.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.5.1+cu124)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.12.0)\n",
            "Requirement already satisfied: torchaudio>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.67.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote.audio) (0.12.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote.audio) (2.5.0.post0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.1)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (4.25.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.38)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.5.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.18.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.1.1)\n",
            "Using cached speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
            "Installing collected packages: speechbrain\n",
            "  Attempting uninstall: speechbrain\n",
            "    Found existing installation: speechbrain 0.5.16\n",
            "    Uninstalling speechbrain-0.5.16:\n",
            "      Successfully uninstalled speechbrain-0.5.16\n",
            "Successfully installed speechbrain-1.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "speechbrain"
                ]
              },
              "id": "7a419c97df8a479d9d2b805d64407c5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: whisper in /usr/local/lib/python3.11/dist-packages (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: ctranslate2==4.4.0 in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2==4.4.0) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2==4.4.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2==4.4.0) (6.0.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "^C\n",
            "^C\n",
            "^C\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain==0.5.16\n",
        "!pip install faster-whisper\n",
        "!pip install pyannote.audio\n",
        "!pip install whisper\n",
        "!pip install ctranslate2==4.4.0\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install speechbrain==0.5.16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FKwNAAaNPLji",
        "outputId": "14440ff5-d8e6-4c7e-aeda-1607cf09b654"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain==0.5.16\n",
            "  Using cached speechbrain-0.5.16-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.16) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.16) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.16) (2.32.3)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain==0.5.16) (0.18.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.16) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.16) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.16) (2025.1.31)\n",
            "Using cached speechbrain-0.5.16-py3-none-any.whl (630 kB)\n",
            "Installing collected packages: speechbrain\n",
            "  Attempting uninstall: speechbrain\n",
            "    Found existing installation: speechbrain 1.0.2\n",
            "    Uninstalling speechbrain-1.0.2:\n",
            "      Successfully uninstalled speechbrain-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyannote-audio 3.3.2 requires speechbrain>=1.0.0, but you have speechbrain 0.5.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed speechbrain-0.5.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "speechbrain"
                ]
              },
              "id": "aded5d06ec8f44f1842a2c5192fff2bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Import libraries  "
      ],
      "metadata": {
        "id": "q1A370A7M08Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from faster_whisper import WhisperModel\n",
        "import torch\n",
        "import whisper\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "from pyannote.audio import Audio\n",
        "from pyannote.core import Segment\n",
        "import speechbrain\n",
        "import ctranslate2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import datetime\n",
        "import re\n",
        "import time\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import traceback\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "# from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(f\"Imports completed successfully at {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwroxjVrMi4Z",
        "outputId": "7ede68b6-306e-4cef-cec5-54126c188d99"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports completed successfully at 2025-02-26 21:17:01.574921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "# print(whisper.__version__)\n",
        "print(speechbrain.__version__)\n",
        "print(ctranslate2.__version__)\n",
        "print(librosa.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCFDG8wINtqV",
        "outputId": "72374cc5-24a0-4be9-f720-3b336ea758b7"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "1.0.2\n",
            "4.4.0\n",
            "0.10.2.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Define helper functions  "
      ],
      "metadata": {
        "id": "Bc0xesFxObkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_time(secs):\n",
        "  '''This function is for converting time in seconds into a human-readable format, specifically'''\n",
        "  return datetime.timedelta(seconds=round(secs))"
      ],
      "metadata": {
        "id": "FJKSKwbFOa1B"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_file, model_name=\"base\", language=\"en\", beam_size=5, best_of=5):\n",
        "  '''This function handles the audio transcription process using the faster-whisper library.'''\n",
        "  try:\n",
        "    # Load the model (Note: we are using fast_whisper modeel)\n",
        "    model = WhisperModel(model_name, compute_type=\"int8\")   # Optionally can specify device='cuda' to use GPU if available\n",
        "\n",
        "    # # Note the start time\n",
        "    # time_start = time.time()\n",
        "\n",
        "    # # Get duration\n",
        "    # audio_data, sample_rate = librosa.load(audio_file, sr=16000, mono=True)\n",
        "    # # duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
        "    # duration = len(audio_data) / sample_rate\n",
        "\n",
        "    # Transcribe the audio\n",
        "    segments_raw, info = model.transcribe(audio_file,\n",
        "                                      task=\"transcribe\",\n",
        "                                      language=language,\n",
        "                                      beam_size=beam_size,\n",
        "                                      best_of=best_of)\n",
        "\n",
        "    # Format the output of transcription into a list of dictionaries\n",
        "    # Each dictionary should represent a segment and contain start time, end time and (optional) text of the segment\n",
        "    segments = []\n",
        "    for segment in segments_raw:\n",
        "      segments.append({\n",
        "          \"start\": segment.start,\n",
        "          \"end\": segment.end,\n",
        "          \"text\": segment.text\n",
        "      })\n",
        "\n",
        "    return segments\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during transcription: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "U37dWX2jOiwD"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_segment_embedding(audio_file, segment, total_duration, embedding_model):\n",
        "  '''This function extracts a speaker embedding for a specific segment of an audio file using a pre-trained speaker embedding model.'''\n",
        "  try:\n",
        "    # Crop the audio file to the segment\n",
        "    start = segment['start']\n",
        "    end = min(total_duration, segment[\"end\"])\n",
        "    clip = Segment(start, end)\n",
        "\n",
        "    audio = Audio()\n",
        "    waveform, sample_rate = audio.crop(audio_file, clip)\n",
        "\n",
        "    # # Instantiate embedding model (part of pyannote library)    # Will be done in the final pipeline\n",
        "    # embedding_model = PretrainedSpeakerEmbedding(\n",
        "    #     \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    #     device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "    # Extract embedding\n",
        "    # The speaker embedding model expects input with a batch dimension. Add a batch dimension to the waveform using 'waveform[None]'\n",
        "    embedding = embedding_model(waveform[None])\n",
        "\n",
        "    # Remove the batch dimension from the embedding using squeeze() to get a 1D embedding vector.\n",
        "    embedding = embedding.squeeze()\n",
        "\n",
        "    # Return the speaker embedding as a NumPy array (Use only if running on GPU!)\n",
        "    # embedding = embedding.detach().cpu().numpy()\n",
        "\n",
        "    return embedding\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during embedding extraction: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "2M2IoCV9O5HJ"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_segment_embeddings(audio_file, segments, embedding_model):\n",
        "  '''This function iterates through all transcribed segments of an audio file and computes speaker embeddings for each segment.'''\n",
        "  try:\n",
        "    # Note the start time\n",
        "    time_start = time.time()\n",
        "\n",
        "    # Get total duration of the audio file\n",
        "    audio_data, sample_rate = librosa.load(audio_file, sr=16000, mono=True)\n",
        "    # total_duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
        "    total_duration = len(audio_data) / sample_rate\n",
        "\n",
        "    #\n",
        "    segment_embeddings = []\n",
        "    for segment in segments:\n",
        "      embedding = extract_segment_embedding(audio_file, segment, total_duration, embedding_model)\n",
        "      segment_embeddings.append(embedding)\n",
        "\n",
        "    # Stack all the embeddings into a 2D NumPy array where each row is an embedding vector.\n",
        "    segment_embeddings = np.stack(segment_embeddings)\n",
        "    print(f\"Segment embeddings shape: {segment_embeddings.shape}\")\n",
        "    print(f\"Time taken to compute segment embeddings: {time.time() - time_start}\")\n",
        "\n",
        "    # Return the 2D array of segment embeddings and the duration of the audio file.\n",
        "    return segment_embeddings, total_duration\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during embedding computation: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "ky-C3rWyQCAs"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_embeddings(embeddings, n_clusters):\n",
        "  '''This function clusters the computed segment embeddings using KMeans to group segments likely spoken by the same speaker.'''\n",
        "  try:\n",
        "    # Fit a KMeans model to embeddings\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    kmeans.fit_predict(embeddings)\n",
        "\n",
        "    # Get labels and centroids\n",
        "    labels = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    print(f\"KMeans labels: {labels}\")\n",
        "    print(f\"KMeans centroids shape: {centroids.shape}\")\n",
        "    return labels, centroids\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during clustering: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "f2eBjKgmQaZX"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cluster_averages(embeddings, labels, n_clusters):\n",
        "  '''Calculate the average embedding for each cluster. This average embedding represents a cluster's speaker profile.'''\n",
        "  try:\n",
        "    # Calculate the average embedding for each cluster\n",
        "    cluster_average_embeddings = {}\n",
        "    for i in range(n_clusters):\n",
        "      cluster_embeddings = embeddings[labels == i]\n",
        "      cluster_average = np.mean(cluster_embeddings, axis=0)\n",
        "      cluster_average_embeddings[i] = cluster_average\n",
        "\n",
        "    # print(f\"Number of clusters in cluster_average_embeddings: {len(cluster_average_embeddings)}\")\n",
        "    # print(f\"Keys in cluster_average_embeddings: {cluster_average_embeddings.keys()}\")\n",
        "    # print(f\"Shape of one cluster_average_embedding: {cluster_average_embeddings[0].shape}\")\n",
        "    return cluster_average_embeddings\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during computing cluster averages: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "3QDQeog4Qokj"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_known_speaker_embeddings(known_speaker_files, embedding_model):\n",
        "  '''To load audio files of known speakers, compute their speaker embeddings, and store them for speaker identification.'''\n",
        "  try:\n",
        "    known_speaker_embeddings = {}\n",
        "    for speaker_file in known_speaker_files:\n",
        "      # Extract a speaker label from the filename (e.g., if the file is \"speaker_A.wav\", the label is \"speaker_A\").\n",
        "      speaker_label = os.path.splitext(os.path.basename(speaker_file))[0]\n",
        "\n",
        "      # Load the audio file using librosa.load()\n",
        "      audio_data, sample_rate = librosa.load(speaker_file, sr=16000, mono=True)\n",
        "      duration = len(audio_data) / sample_rate\n",
        "\n",
        "      # Create a segment object covering the entire duration of the loaded audio.\n",
        "      # Crop the audio using this segment\n",
        "      segment = Segment(0, duration)\n",
        "\n",
        "      audio = Audio()\n",
        "      waveform, sample_rate = audio.crop(speaker_file, segment)\n",
        "\n",
        "      # Extract embedding\n",
        "      embedding = embedding_model(waveform[None])\n",
        "      embedding = embedding.squeeze()\n",
        "      # embedding = embedding.detach().cpu().numpy()    # Use this line only if you are runniing code on GPU\n",
        "\n",
        "      # Store the embedding in the dictionary with the corresponding speaker label as the key.\n",
        "      known_speaker_embeddings[speaker_label] = embedding\n",
        "\n",
        "    # Return a dictionary of known speaker embeddings where keys are speaker labels and values are their embedding vectors.\n",
        "    return known_speaker_embeddings\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during loading known speaker embeddings: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "HD2FzYtQQ6DR"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_speaker_labels(cluster_avg_embeddings, known_speaker_embeddings, similarity_threshold=0.7):\n",
        "  '''Compare average embeddings of clusters with embeddings of known speakers to assign speaker labels to clusters.'''\n",
        "  try:\n",
        "    # Initialize an empty dictionary to map cluster IDs to speaker labels and cosine similarity.\n",
        "    speaker_labels = {}\n",
        "    similarity_scores_per_cluster = {}\n",
        "\n",
        "    # Iterate through each cluster ID\n",
        "    for cluster_id, cluster_avg_embedding in cluster_avg_embeddings.items():\n",
        "      # Add default label as 'Unkown'\n",
        "      speaker_labels[cluster_id] = (\"Unknown\", 0)\n",
        "      # Best cosine_similarity\n",
        "      similarity_scores = []\n",
        "\n",
        "      # Iterate through each known speaker embedding\n",
        "      for speaker_label, speaker_embedding in known_speaker_embeddings.items():\n",
        "        # Calculate the cosine similarity between the cluster average embedding and the speaker embedding.\n",
        "        # Use cosine_similarity from sklearn.metrics.pairwise\n",
        "        # print(f\"Shape of cluster_avg_embedding: {cluster_avg_embedding.shape}\")\n",
        "        # print(f\"Shape of speaker_embedding: {speaker_embedding.shape}\")\n",
        "\n",
        "        # Remember to reshape embeddings to 2D arrays before using cosine_similarity\n",
        "        similarity = cosine_similarity(cluster_avg_embedding.reshape(1, -1), speaker_embedding.reshape(1, -1))\n",
        "        # print(f\"Similarity: {similarity}\")\n",
        "        similarity_scores.append(similarity)\n",
        "\n",
        "        # If the similarity is above the threshold, assign the cluster to the speaker label\n",
        "        if similarity >= similarity_threshold:\n",
        "          print(f\"Similarity: {similarity}\")\n",
        "          speaker_labels[cluster_id] = [speaker_label, similarity]\n",
        "\n",
        "      similarity_scores_per_cluster[cluster_id] = similarity_scores\n",
        "      print(f\"Similarity scores for cluster {cluster_id}: {similarity_scores}\")\n",
        "    return speaker_labels, similarity_scores_per_cluster\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during assigning speaker labels: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "BRQ6LKjvRJtl"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(audio_file, embedding_model, known_speaker_embeddings, n_clusters=3, whisper_model_name=\"base\", similarity_threshold=0.7):\n",
        "  '''This function orchestrates the entire speaker diarization and identification pipeline, calling all the\n",
        "  previously defined functions in the correct sequence.'''\n",
        "  try:\n",
        "    # Print a separator and a message indicating the processing of the current audio_file\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Processing audio file: {audio_file}\")\n",
        "\n",
        "    # Transcribe audio\n",
        "    segments = transcribe_audio(audio_file, model_name=whisper_model_name)\n",
        "\n",
        "    # Compute segment embeddings\n",
        "    segment_embeddings, total_duration = compute_segment_embeddings(audio_file, segments, embedding_model)\n",
        "\n",
        "    # Get cluster embeddings\n",
        "    labels, centroids = cluster_embeddings(segment_embeddings, n_clusters)\n",
        "\n",
        "    # Compute cluster averages\n",
        "    cluster_avg_embeddings = compute_cluster_averages(segment_embeddings, labels, n_clusters)\n",
        "\n",
        "    # Load known speaker embeddings\n",
        "    # known_speaker_embeddings = load_known_speaker_embeddings(known_speaker_embeddings, embedding_model)\n",
        "\n",
        "    # Assign speaker labels\n",
        "    speaker_labels, similarity_scores_per_cluster = assign_speaker_labels(cluster_avg_embeddings, known_speaker_embeddings, similarity_threshold)\n",
        "    print(f\"The Speaker labels dictionary is: {speaker_labels}\")\n",
        "\n",
        "    # Annotate each segment with its cluster ID and assign speaker ID\n",
        "    for i, segment in enumerate(segments):\n",
        "      segment['cluster_id'] = labels[i]\n",
        "      segment['speaker_id'] = speaker_labels[labels[i]][0]\n",
        "      segment['similarity'] = speaker_labels[labels[i]][1]\n",
        "      segment['max_similarity_score'] = max(similarity_scores_per_cluster[labels[i]])\n",
        "\n",
        "    # Format the results into a Pandas DataFrame. The DataFrame should contain columns for \"Start\", \"End\", \"Cluster\", and \"Speaker_ID\".\n",
        "    # Convert start and end times to hh:mm:ss format using convert_time.\n",
        "    df = pd.DataFrame(segments)\n",
        "    df['Start'] = df['start'].apply(convert_time)\n",
        "    df['End'] = df['end'].apply(convert_time)\n",
        "    df = df.drop(columns=['start', 'end'])\n",
        "    print(df)\n",
        "\n",
        "    # Group consecutive segments with the same speaker ID to produce a diarization-like output.\n",
        "    df_grouped = df.groupby(['cluster_id', 'speaker_id']).agg({'Start': 'first', 'End': 'last'}).reset_index()\n",
        "    # Print the resulting DataFrame.\n",
        "    print(df_grouped)\n",
        "\n",
        "    # Print separator\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Return the results DataFrame, the number of segments transcribed, and the cluster centroids.\n",
        "    return df, len(segments), centroids, df_grouped\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during the final pipeline execution: {e}\")\n",
        "    traceback.print_exc()\n",
        "    return None"
      ],
      "metadata": {
        "id": "rycjvkkKRdcd"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Loading models and data  "
      ],
      "metadata": {
        "id": "8gCGQ7bRSCmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to CPU\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "o6zT7qttSEab"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speechbrain.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jx0vYEpclQ11",
        "outputId": "4df2139b-101d-46f4-b24e-e9f816300065"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.0.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embedding model\n",
        "embedding_model = PretrainedSpeakerEmbedding(\n",
        "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    device=device)\n",
        "embedding_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StAJoe5kk8EP",
        "outputId": "d022e0e0-43f3-4d20-9330-d80c79219e49"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stats = torch.load(path, map_location=device)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyannote.audio.pipelines.speaker_verification.SpeechBrainPretrainedSpeakerEmbedding at 0x7eb870634290>"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a file from my Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GgWfC4zlwXz",
        "outputId": "5b6d3fc2-f15a-4e87-fbd0-7752ad2c50f9"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Untar wavs.tar.gz\n",
        "!tar -xvf /content/drive/MyDrive/DLP/GA/week_6/wavs.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_QHyMRTm_R9",
        "outputId": "e585424a-7684-4bd3-ec00-2f18c6a14513"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speaker_A.wav\n",
            "speaker_B.wav\n",
            "speaker_C.wav\n",
            "speaker_D.wav\n",
            "speaker_E.wav\n",
            "sample.wav\n",
            "sample_noisy.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get known speaker embeddings\n",
        "known_speaker_files = [\"speaker_A.wav\", \"speaker_B.wav\", \"speaker_C.wav\", \"speaker_D.wav\", \"speaker_E.wav\"]\n",
        "\n",
        "known_speaker_embeddings = load_known_speaker_embeddings(known_speaker_files, embedding_model)\n",
        "\n",
        "len(known_speaker_embeddings), known_speaker_embeddings.keys(), known_speaker_embeddings['speaker_A'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXVU1lS_oQtQ",
        "outputId": "f358d5a0-8879-4194-a572-294b7670afc3"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " dict_keys(['speaker_A', 'speaker_B', 'speaker_C', 'speaker_D', 'speaker_E']),\n",
              " (192,))"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V. Processing audio samples  "
      ],
      "metadata": {
        "id": "LvLiHzmESLTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 'clean' audio sample  "
      ],
      "metadata": {
        "id": "KI78XmvKpaSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the clean audio file\n",
        "clean_audio = \"sample.wav\"\n",
        "clean_audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3Pq3II4iSPUv",
        "outputId": "e9e43869-c662-45d3-b5f8-75901c242692"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sample.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline with clean_audio, embedding_model, known_speaker_embeddings, n_clusters=3, whisper_model_name=\"base\", similarity_threshold=0.7\n",
        "\n",
        "df_clean, n_segments_clean, centroids_clean, df_clean_grouped = run_pipeline(clean_audio,\n",
        "                                                           embedding_model,\n",
        "                                                           known_speaker_embeddings,\n",
        "                                                           n_clusters=3,\n",
        "                                                           whisper_model_name=\"base\",\n",
        "                                                           similarity_threshold=0.7)\n",
        "\n",
        "print(f\"Number of segments transcribed: {n_segments_clean}\")\n",
        "print(f\"Cluster centroids: {centroids_clean.shape}\")\n",
        "print(df_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzFTPoeppzwt",
        "outputId": "d54ffaad-140a-477b-e462-9312a104938e"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Processing audio file: sample.wav\n",
            "Segment embeddings shape: (6, 192)\n",
            "Time taken to compute segment embeddings: 4.107895374298096\n",
            "KMeans labels: [2 1 0 1 0 2]\n",
            "KMeans centroids shape: (3, 192)\n",
            "Similarity scores for cluster 0: [array([[0.68920267]], dtype=float32), array([[0.07233772]], dtype=float32), array([[0.07125822]], dtype=float32), array([[0.03393675]], dtype=float32), array([[0.21205282]], dtype=float32)]\n",
            "Similarity: [[0.79727113]]\n",
            "Similarity scores for cluster 1: [array([[0.17268004]], dtype=float32), array([[0.07001918]], dtype=float32), array([[0.79727113]], dtype=float32), array([[0.16717166]], dtype=float32), array([[0.10807592]], dtype=float32)]\n",
            "Similarity: [[0.85755897]]\n",
            "Similarity scores for cluster 2: [array([[-0.06704538]], dtype=float32), array([[0.85755897]], dtype=float32), array([[0.17290641]], dtype=float32), array([[0.25017476]], dtype=float32), array([[0.2543853]], dtype=float32)]\n",
            "The Speaker labels dictionary is: {0: ('Unknown', 0), 1: ['speaker_C', array([[0.79727113]], dtype=float32)], 2: ['speaker_B', array([[0.85755897]], dtype=float32)]}\n",
            "                                                text  cluster_id speaker_id  \\\n",
            "0   This device picked up the same amount of musk...           2  speaker_B   \n",
            "1   Raising front-down would likely produce simil...           1  speaker_C   \n",
            "2                                Do you doubt Homer?           0    Unknown   \n",
            "3   One can also build cords by stacking fifths y...           1  speaker_C   \n",
            "4   Forget Apollo, he said, with his suggestion o...           0    Unknown   \n",
            "5   Biconical bots with cylindrical necks are esp...           2  speaker_B   \n",
            "\n",
            "       similarity max_similarity_score           Start             End  \n",
            "0  [[0.85755897]]       [[0.85755897]] 0 days 00:00:00 0 days 00:00:06  \n",
            "1  [[0.79727113]]       [[0.79727113]] 0 days 00:00:08 0 days 00:00:14  \n",
            "2               0       [[0.68920267]] 0 days 00:00:15 0 days 00:00:17  \n",
            "3  [[0.79727113]]       [[0.79727113]] 0 days 00:00:18 0 days 00:00:24  \n",
            "4               0       [[0.68920267]] 0 days 00:00:25 0 days 00:00:29  \n",
            "5  [[0.85755897]]       [[0.85755897]] 0 days 00:00:31 0 days 00:00:36  \n",
            "   cluster_id speaker_id           Start             End\n",
            "0           0    Unknown 0 days 00:00:15 0 days 00:00:29\n",
            "1           1  speaker_C 0 days 00:00:08 0 days 00:00:24\n",
            "2           2  speaker_B 0 days 00:00:00 0 days 00:00:36\n",
            "--------------------------------------------------\n",
            "Number of segments transcribed: 6\n",
            "Cluster centroids: (3, 192)\n",
            "                                                text  cluster_id speaker_id  \\\n",
            "0   This device picked up the same amount of musk...           2  speaker_B   \n",
            "1   Raising front-down would likely produce simil...           1  speaker_C   \n",
            "2                                Do you doubt Homer?           0    Unknown   \n",
            "3   One can also build cords by stacking fifths y...           1  speaker_C   \n",
            "4   Forget Apollo, he said, with his suggestion o...           0    Unknown   \n",
            "5   Biconical bots with cylindrical necks are esp...           2  speaker_B   \n",
            "\n",
            "       similarity max_similarity_score           Start             End  \n",
            "0  [[0.85755897]]       [[0.85755897]] 0 days 00:00:00 0 days 00:00:06  \n",
            "1  [[0.79727113]]       [[0.79727113]] 0 days 00:00:08 0 days 00:00:14  \n",
            "2               0       [[0.68920267]] 0 days 00:00:15 0 days 00:00:17  \n",
            "3  [[0.79727113]]       [[0.79727113]] 0 days 00:00:18 0 days 00:00:24  \n",
            "4               0       [[0.68920267]] 0 days 00:00:25 0 days 00:00:29  \n",
            "5  [[0.85755897]]       [[0.85755897]] 0 days 00:00:31 0 days 00:00:36  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1  \n",
        "`For the clean audio sample (\"sample.wav\"), the three clusters have best cosine similarity scores of a, b, and c. Calculate the average cosine similarity score across all clusters (round to three decimal places).\n",
        "`"
      ],
      "metadata": {
        "id": "C0JC8iI2ABsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean([0.85755897, 0.79727113, 0.68920267])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO2aQWtmA13Q",
        "outputId": "f71de059-7dd5-4bb2-97fc-3f18bae8b5ff"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7813442566666667"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1\n",
        "avg_best_cos_sim_clean = np.unique(df_clean['max_similarity_score']).mean()\n",
        "print(f\"{avg_best_cos_sim_clean[0][0]: .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W5l7rBE_7Ef",
        "outputId": "b38b1700-4013-4e56-fdec-6b11bc4667d3"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(df_clean['max_similarity_score']).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYfKF8JxCrho",
        "outputId": "64b3790f-c137-4ff3-bc88-7257fc5a4e87"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.78134423]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3  "
      ],
      "metadata": {
        "id": "WAu99vqYDlZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`If a similarity threshold of 0.7 is required for reliable speaker identification, how many clusters in the clean sample meet or exceed this threshold?`"
      ],
      "metadata": {
        "id": "zrxafEyzDy1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[df_clean['max_similarity_score'] >= 0.7]['cluster_id'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sFptV5GD5vM",
        "outputId": "7def3fd2-8e28-4c5f-e564-7c5af68a21ec"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[df_clean['max_similarity_score'] >= 0.7][['cluster_id', 'max_similarity_score']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "jVgUtv5REkKz",
        "outputId": "8b694000-47fc-42f9-9510-93b2855eff01"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cluster_id max_similarity_score\n",
              "0           2       [[0.85755897]]\n",
              "1           1       [[0.79727113]]\n",
              "3           1       [[0.79727113]]\n",
              "5           2       [[0.85755897]]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fccd7d1-97fe-4cf7-ab11-eb3c3fe15b21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster_id</th>\n",
              "      <th>max_similarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[[0.85755897]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.79727113]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[[0.79727113]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>[[0.85755897]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fccd7d1-97fe-4cf7-ab11-eb3c3fe15b21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fccd7d1-97fe-4cf7-ab11-eb3c3fe15b21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fccd7d1-97fe-4cf7-ab11-eb3c3fe15b21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0257451c-5aef-4700-87c5-5662d6664a32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0257451c-5aef-4700-87c5-5662d6664a32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0257451c-5aef-4700-87c5-5662d6664a32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_clean[df_clean['max_similarity_score'] >= 0\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"cluster_id\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_similarity_score\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_grouped['speaker_id'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "-EOhOyb5DkVf",
        "outputId": "9774e58b-888d-4cb9-90bf-f269bfa2c011"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speaker_id\n",
              "Unknown      1\n",
              "speaker_C    1\n",
              "speaker_B    1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speaker_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unknown</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speaker_C</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speaker_B</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6  "
      ],
      "metadata": {
        "id": "WJ4KrxUZFb0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Using the diarization results for the clean sample, compute the total duration (in seconds) covered by all the transcribed segments.`"
      ],
      "metadata": {
        "id": "CjaoGoc6FblR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(max(df_clean['End']) - min(df_clean['Start'])).total_seconds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH3bhdP7FuKQ",
        "outputId": "1d994512-24b7-4d03-d361-3d07c010dc2d"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.0"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8  "
      ],
      "metadata": {
        "id": "FQNNwCDbHBdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Examining the clustering results for the clean sample, which cluster shows the highest confidence (i.e. the highest cosine similarity), and what known speaker label is it matched with?`"
      ],
      "metadata": {
        "id": "UoqEFvFrHBVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[df_clean['max_similarity_score'] == df_clean['max_similarity_score'][0][0].max()][['cluster_id', 'speaker_id', 'max_similarity_score']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Vom2YQBdHF1Z",
        "outputId": "6e6218ab-0621-4868-beed-3e8e83a28dde"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cluster_id speaker_id max_similarity_score\n",
              "0           2  speaker_B       [[0.85755897]]\n",
              "5           2  speaker_B       [[0.85755897]]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f558778-ee3e-4c54-9ccf-e379c31c9256\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster_id</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>max_similarity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>speaker_B</td>\n",
              "      <td>[[0.85755897]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>speaker_B</td>\n",
              "      <td>[[0.85755897]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f558778-ee3e-4c54-9ccf-e379c31c9256')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f558778-ee3e-4c54-9ccf-e379c31c9256 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f558778-ee3e-4c54-9ccf-e379c31c9256');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37d8ddc7-9419-4292-aed5-78b3b676a46c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37d8ddc7-9419-4292-aed5-78b3b676a46c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37d8ddc7-9419-4292-aed5-78b3b676a46c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_clean[df_clean['max_similarity_score'] == df_clean['max_similarity_score'][0][0]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"cluster_id\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"speaker_B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_similarity_score\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 'noisy' audio sample  "
      ],
      "metadata": {
        "id": "v5eBnhKfpeb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the noisy audio file\n",
        "noisy_audio = \"sample_noisy.wav\"\n",
        "noisy_audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6a1Q2Q665J06",
        "outputId": "65f4a498-7c61-42ab-fdf6-233a2c5c4836"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sample_noisy.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline with noisy_audio, embedding_model, known_speaker_embeddings, n_clusters=3, whisper_model_name=\"base\", similarity_threshold=0.7\n",
        "\n",
        "df_noisy, n_segments_noisy, centroids_noisy, df_noisy_grouped = run_pipeline(noisy_audio,\n",
        "                                                           embedding_model,\n",
        "                                                           known_speaker_embeddings,\n",
        "                                                           n_clusters=3,\n",
        "                                                           whisper_model_name=\"base\",\n",
        "                                                           similarity_threshold=0.7)\n",
        "\n",
        "print(f\"Number of segments transcribed: {n_segments_noisy}\")\n",
        "print(f\"Cluster centroids: {centroids_noisy.shape}\")\n",
        "print(df_noisy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUtaQnIphXI",
        "outputId": "40940a87-cbe4-41ce-e61e-2c612ee5b16c"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Processing audio file: sample_noisy.wav\n",
            "Segment embeddings shape: (8, 192)\n",
            "Time taken to compute segment embeddings: 3.767221689224243\n",
            "KMeans labels: [2 1 0 1 1 0 0 2]\n",
            "KMeans centroids shape: (3, 192)\n",
            "Similarity scores for cluster 0: [array([[0.5812957]], dtype=float32), array([[0.0349585]], dtype=float32), array([[-0.06661911]], dtype=float32), array([[0.01783739]], dtype=float32), array([[0.07180018]], dtype=float32)]\n",
            "Similarity scores for cluster 1: [array([[0.04861312]], dtype=float32), array([[0.1614371]], dtype=float32), array([[0.5451888]], dtype=float32), array([[0.15152594]], dtype=float32), array([[0.01892857]], dtype=float32)]\n",
            "Similarity scores for cluster 2: [array([[-0.07635162]], dtype=float32), array([[0.6756178]], dtype=float32), array([[0.06061047]], dtype=float32), array([[0.13118726]], dtype=float32), array([[0.15789184]], dtype=float32)]\n",
            "The Speaker labels dictionary is: {0: ('Unknown', 0), 1: ('Unknown', 0), 2: ('Unknown', 0)}\n",
            "                                                text  cluster_id speaker_id  \\\n",
            "0   This device picked up the same amount of must...           2    Unknown   \n",
            "1   Raising fine sand is likely to be a scenario ...           1    Unknown   \n",
            "2                                Do you doubt Homan?           0    Unknown   \n",
            "3        One can also build cores by striking fifth.           1    Unknown   \n",
            "4                       You have been control Homan.           1    Unknown   \n",
            "5                          Forget a follow, he said.           0    Unknown   \n",
            "6         With his suggestion of severity and voice.           0    Unknown   \n",
            "7   Biconical bots with cylindrical necks are esp...           2    Unknown   \n",
            "\n",
            "   similarity max_similarity_score           Start             End  \n",
            "0           0        [[0.6756178]] 0 days 00:00:00 0 days 00:00:05  \n",
            "1           0        [[0.5451888]] 0 days 00:00:08 0 days 00:00:13  \n",
            "2           0        [[0.5812957]] 0 days 00:00:15 0 days 00:00:17  \n",
            "3           0        [[0.5451888]] 0 days 00:00:18 0 days 00:00:21  \n",
            "4           0        [[0.5451888]] 0 days 00:00:21 0 days 00:00:23  \n",
            "5           0        [[0.5812957]] 0 days 00:00:25 0 days 00:00:27  \n",
            "6           0        [[0.5812957]] 0 days 00:00:27 0 days 00:00:29  \n",
            "7           0        [[0.6756178]] 0 days 00:00:30 0 days 00:00:35  \n",
            "   cluster_id speaker_id           Start             End\n",
            "0           0    Unknown 0 days 00:00:15 0 days 00:00:29\n",
            "1           1    Unknown 0 days 00:00:08 0 days 00:00:23\n",
            "2           2    Unknown 0 days 00:00:00 0 days 00:00:35\n",
            "--------------------------------------------------\n",
            "Number of segments transcribed: 8\n",
            "Cluster centroids: (3, 192)\n",
            "                                                text  cluster_id speaker_id  \\\n",
            "0   This device picked up the same amount of must...           2    Unknown   \n",
            "1   Raising fine sand is likely to be a scenario ...           1    Unknown   \n",
            "2                                Do you doubt Homan?           0    Unknown   \n",
            "3        One can also build cores by striking fifth.           1    Unknown   \n",
            "4                       You have been control Homan.           1    Unknown   \n",
            "5                          Forget a follow, he said.           0    Unknown   \n",
            "6         With his suggestion of severity and voice.           0    Unknown   \n",
            "7   Biconical bots with cylindrical necks are esp...           2    Unknown   \n",
            "\n",
            "   similarity max_similarity_score           Start             End  \n",
            "0           0        [[0.6756178]] 0 days 00:00:00 0 days 00:00:05  \n",
            "1           0        [[0.5451888]] 0 days 00:00:08 0 days 00:00:13  \n",
            "2           0        [[0.5812957]] 0 days 00:00:15 0 days 00:00:17  \n",
            "3           0        [[0.5451888]] 0 days 00:00:18 0 days 00:00:21  \n",
            "4           0        [[0.5451888]] 0 days 00:00:21 0 days 00:00:23  \n",
            "5           0        [[0.5812957]] 0 days 00:00:25 0 days 00:00:27  \n",
            "6           0        [[0.5812957]] 0 days 00:00:27 0 days 00:00:29  \n",
            "7           0        [[0.6756178]] 0 days 00:00:30 0 days 00:00:35  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2  \n",
        "`\n",
        "For the noisy audio sample (\"sample_noisy.wav\"), the clusters have best similarity scores of x, y, z. Calculate the average cosine similarity score across these clusters (round to three decimal places).`"
      ],
      "metadata": {
        "id": "GSVfFEJiB9iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean([0.5812957, 0.5451888, 0.6756178])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqM1s2VtCMqb",
        "outputId": "46ff591f-8546-4271-d969-2e03b5c21db8"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6007007666666667"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1\n",
        "avg_best_cos_sim_noisy = np.unique(df_noisy['max_similarity_score']).mean()\n",
        "print(f\"{avg_best_cos_sim_noisy[0][0]: .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8swiJXNkCDBH",
        "outputId": "0ac60c9f-c893-43c1-ad6e-c0ce94f59208"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4  "
      ],
      "metadata": {
        "id": "1tZcawTTEzqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Using the same similarity threshold (0.7), how many clusters in the noisy sample would be considered reliably matched?`"
      ],
      "metadata": {
        "id": "l9tN7lF6E11K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_noisy[df_noisy['max_similarity_score'] >= 0.7]['cluster_id'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aQloDjCE5PE",
        "outputId": "f2ee518e-bf68-440c-9592-ff54879169e9"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5  "
      ],
      "metadata": {
        "id": "Utf7-cnEE_-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`\n",
        "The transcription produced m segments for \"sample.wav\" and n segments for \"sample_noisy.wav.\" Calculate the percentage increase in the number of segments in the noisy sample relative to the clean sample (round to tw0 decimal place).`  "
      ],
      "metadata": {
        "id": "-sOz9DgfFBvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.shape[0], df_noisy.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNN4LLSnFEIV",
        "outputId": "d647d424-abaa-41c2-ddbf-fb4cbec2011a"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df_noisy.shape[0] - df_clean.shape[0])/df_clean.shape[0] * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wGKHsrYFNkT",
        "outputId": "36f390ca-4adc-4dbf-c098-7764de5ccfa8"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.33333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7  "
      ],
      "metadata": {
        "id": "c47kjbrhGKQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`If the similarity threshold were reduced from 0.7 to 0.65, which cluster in the noisy sample would now be assigned a known speaker label instead of \"Unknown\"?`"
      ],
      "metadata": {
        "id": "s6BcdVBnGKFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline with noisy_audio with similarity threshold 0.65\n",
        "\n",
        "df_noisy_65, n_segments_noisy_65, centroids_noisy_65, df_noisy_65_grouped = run_pipeline(noisy_audio,\n",
        "                                                           embedding_model,\n",
        "                                                           known_speaker_embeddings,\n",
        "                                                           n_clusters=3,\n",
        "                                                           whisper_model_name=\"base\",\n",
        "                                                           similarity_threshold=0.65)\n",
        "\n",
        "print(f\"Number of segments transcribed: {n_segments_noisy_65}\")\n",
        "print(f\"Cluster centroids: {centroids_noisy_65.shape}\")\n",
        "print(df_noisy_65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXlM2raQ6LI0",
        "outputId": "eea307fd-9e23-42f1-8175-88a3e06c296a"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Processing audio file: sample_noisy.wav\n",
            "Segment embeddings shape: (8, 192)\n",
            "Time taken to compute segment embeddings: 3.769523859024048\n",
            "KMeans labels: [2 1 0 1 1 0 0 2]\n",
            "KMeans centroids shape: (3, 192)\n",
            "Similarity scores for cluster 0: [array([[0.5812957]], dtype=float32), array([[0.0349585]], dtype=float32), array([[-0.06661911]], dtype=float32), array([[0.01783739]], dtype=float32), array([[0.07180018]], dtype=float32)]\n",
            "Similarity scores for cluster 1: [array([[0.04861312]], dtype=float32), array([[0.1614371]], dtype=float32), array([[0.5451888]], dtype=float32), array([[0.15152594]], dtype=float32), array([[0.01892857]], dtype=float32)]\n",
            "Similarity: [[0.6756178]]\n",
            "Similarity scores for cluster 2: [array([[-0.07635162]], dtype=float32), array([[0.6756178]], dtype=float32), array([[0.06061047]], dtype=float32), array([[0.13118726]], dtype=float32), array([[0.15789184]], dtype=float32)]\n",
            "The Speaker labels dictionary is: {0: ('Unknown', 0), 1: ('Unknown', 0), 2: ['speaker_B', array([[0.6756178]], dtype=float32)]}\n",
            "                                                text  cluster_id speaker_id  \\\n",
            "0   This device picked up the same amount of must...           2  speaker_B   \n",
            "1   Raising fine sand is likely to be a scenario ...           1    Unknown   \n",
            "2                                Do you doubt Homan?           0    Unknown   \n",
            "3        One can also build cores by striking fifth.           1    Unknown   \n",
            "4                       You have been control Homan.           1    Unknown   \n",
            "5                          Forget a follow, he said.           0    Unknown   \n",
            "6         With his suggestion of severity and voice.           0    Unknown   \n",
            "7   Biconical bots with cylindrical necks are esp...           2  speaker_B   \n",
            "\n",
            "      similarity max_similarity_score           Start             End  \n",
            "0  [[0.6756178]]        [[0.6756178]] 0 days 00:00:00 0 days 00:00:05  \n",
            "1              0        [[0.5451888]] 0 days 00:00:08 0 days 00:00:13  \n",
            "2              0        [[0.5812957]] 0 days 00:00:15 0 days 00:00:17  \n",
            "3              0        [[0.5451888]] 0 days 00:00:18 0 days 00:00:21  \n",
            "4              0        [[0.5451888]] 0 days 00:00:21 0 days 00:00:23  \n",
            "5              0        [[0.5812957]] 0 days 00:00:25 0 days 00:00:27  \n",
            "6              0        [[0.5812957]] 0 days 00:00:27 0 days 00:00:29  \n",
            "7  [[0.6756178]]        [[0.6756178]] 0 days 00:00:30 0 days 00:00:35  \n",
            "   cluster_id speaker_id           Start             End\n",
            "0           0    Unknown 0 days 00:00:15 0 days 00:00:29\n",
            "1           1    Unknown 0 days 00:00:08 0 days 00:00:23\n",
            "2           2  speaker_B 0 days 00:00:00 0 days 00:00:35\n",
            "--------------------------------------------------\n",
            "Number of segments transcribed: 8\n",
            "Cluster centroids: (3, 192)\n",
            "                                                text  cluster_id speaker_id  \\\n",
            "0   This device picked up the same amount of must...           2  speaker_B   \n",
            "1   Raising fine sand is likely to be a scenario ...           1    Unknown   \n",
            "2                                Do you doubt Homan?           0    Unknown   \n",
            "3        One can also build cores by striking fifth.           1    Unknown   \n",
            "4                       You have been control Homan.           1    Unknown   \n",
            "5                          Forget a follow, he said.           0    Unknown   \n",
            "6         With his suggestion of severity and voice.           0    Unknown   \n",
            "7   Biconical bots with cylindrical necks are esp...           2  speaker_B   \n",
            "\n",
            "      similarity max_similarity_score           Start             End  \n",
            "0  [[0.6756178]]        [[0.6756178]] 0 days 00:00:00 0 days 00:00:05  \n",
            "1              0        [[0.5451888]] 0 days 00:00:08 0 days 00:00:13  \n",
            "2              0        [[0.5812957]] 0 days 00:00:15 0 days 00:00:17  \n",
            "3              0        [[0.5451888]] 0 days 00:00:18 0 days 00:00:21  \n",
            "4              0        [[0.5451888]] 0 days 00:00:21 0 days 00:00:23  \n",
            "5              0        [[0.5812957]] 0 days 00:00:25 0 days 00:00:27  \n",
            "6              0        [[0.5812957]] 0 days 00:00:27 0 days 00:00:29  \n",
            "7  [[0.6756178]]        [[0.6756178]] 0 days 00:00:30 0 days 00:00:35  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_noisy_65[['cluster_id', 'speaker_id']].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "ZsaU9pFjGS3K",
        "outputId": "1d733cca-f0f9-4b93-e474-e92149638774"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cluster_id  speaker_id\n",
              "0           Unknown       3\n",
              "1           Unknown       3\n",
              "2           speaker_B     2\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster_id</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th>Unknown</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <th>Unknown</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <th>speaker_B</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    }
  ]
}