{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:07:00.638672Z","iopub.execute_input":"2025-03-08T11:07:00.639027Z","iopub.status.idle":"2025-03-08T11:07:00.943664Z","shell.execute_reply.started":"2025-03-08T11:07:00.638994Z","shell.execute_reply":"2025-03-08T11:07:00.942787Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/indic-tts-deepfake-challenge/sample.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install transformers datasets torchaudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:07:03.345564Z","iopub.execute_input":"2025-03-08T11:07:03.346000Z","iopub.status.idle":"2025-03-08T11:07:08.653064Z","shell.execute_reply.started":"2025-03-08T11:07:03.345973Z","shell.execute_reply":"2025-03-08T11:07:08.652000Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"SherryT997/IndicTTS-Deepfake-Challenge-Data\")  \n\ntrain_data = dataset[\"train\"] \ntest_data = dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:07:11.513049Z","iopub.execute_input":"2025-03-08T11:07:11.513360Z","iopub.status.idle":"2025-03-08T11:11:39.515879Z","shell.execute_reply.started":"2025-03-08T11:07:11.513335Z","shell.execute_reply":"2025-03-08T11:11:39.515215Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09354c47a54b48a59ff314a57bc54f46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08f525c1b884c3d9ee4f9a1dfa5ebcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1eb45150b545b4b908ee0df94ebe76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/35 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea4b321b9e14b93abf960b934776998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00035.parquet:   0%|          | 0.00/453M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"770f384f770b40afa706d64566e7af25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00035.parquet:   0%|          | 0.00/461M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b86bc2e2a0432e82f83c3a353bd184"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00035.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9202547d7b44cc0a2bd65d9a9151557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00035.parquet:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb343ea9d5e34e219d4f88313c12cb40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00035.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5a3e21f652405c84da6ad59cec71ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00035.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdfd7035079c4a9295ad2baa4c6a614b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00035.parquet:   0%|          | 0.00/447M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"237885ebedb443048ba204ba785b1d8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00035.parquet:   0%|          | 0.00/516M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea6a6cec5e44bca8df11787a07147b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00035.parquet:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4081fb035e7d44fa86fba0e7338376b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00035.parquet:   0%|          | 0.00/521M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2677409e1e3d4fddb049e26af9c8bf6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00035.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50608d553c19443e9a4d821026e498e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00035.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"253215f8e2534e798264a5b5165051b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00035.parquet:   0%|          | 0.00/414M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44943995ca414e298207deec2152ee50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00035.parquet:   0%|          | 0.00/473M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ec24825dc54ea9856d90233558971e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00035.parquet:   0%|          | 0.00/481M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"164f18f65ffc4703a41578dbbdc5a45e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00035.parquet:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abb0f5e123754396a64569022bb9d974"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00035.parquet:   0%|          | 0.00/532M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fcd5b8102b54cdda109124567e8afb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00035.parquet:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a46eaee1a4b744d09f380cab66d88996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00035.parquet:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f723400a4347d39c38b53819bd53dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00035.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e17526190db4815b3a6490dca53db2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00035.parquet:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f041a65eeb444011b97fc7e94a766a01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00035.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f49e780eed76437bb291eee62c8bc5fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00035.parquet:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c3d5519eaff463e847b823310bcef03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00035.parquet:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b94b48245ba64223aa7b9b8934d9f67b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00035.parquet:   0%|          | 0.00/576M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ebf36c1cfb44b69320a4f69bf77c98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00035.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"243da38b9bd14e9d9dc7d008c7762e09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00035.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d5c53bbb5940a3bb1ce11a935e2535"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00035.parquet:   0%|          | 0.00/421M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e9d1f29e604b56a243a87024ab974d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00035.parquet:   0%|          | 0.00/382M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e32d6f7e4cd148caa09b8e415461bd55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00035.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aded8a01bb044188eb988f6f04edf47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00030-of-00035.parquet:   0%|          | 0.00/282M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8ee2c439934bf4a0988eac026d9ef5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00031-of-00035.parquet:   0%|          | 0.00/688M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c9da50f9b6f4b96956cea1dc8367c4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00032-of-00035.parquet:   0%|          | 0.00/613M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877d0e571c4b494f841585429d3ff011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00033-of-00035.parquet:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5f51daa043943f09c63bf8bf1a39776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00034-of-00035.parquet:   0%|          | 0.00/424M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddbc3721bc024056b7ee8d579cb5909d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00004.parquet:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e9f4325e374169af8c53bf3f5304f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00001-of-00004.parquet:   0%|          | 0.00/364M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b6337b7057f4878bf9e2ef547ee5343"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00002-of-00004.parquet:   0%|          | 0.00/410M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a3e7a20f6746b2a8a94eaf9be64c88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00003-of-00004.parquet:   0%|          | 0.00/291M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27e17ce46836407f8dec428c0bdc3c30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/31102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbfb288d73224d9fb0736715756407e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a0d0d595144f0f83933cd6b80bface"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0edf48cc25a94b08ae0fa13524ac7506"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"sample_dataset = train_data.select(range(100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:26:13.867614Z","iopub.execute_input":"2025-03-08T12:26:13.867987Z","iopub.status.idle":"2025-03-08T12:26:13.883231Z","shell.execute_reply.started":"2025-03-08T12:26:13.867955Z","shell.execute_reply":"2025-03-08T12:26:13.882533Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"train_sample = sample_dataset.select(range(90))  \ntest_sample = sample_dataset.select(range(91, 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:26:24.049033Z","iopub.execute_input":"2025-03-08T12:26:24.049332Z","iopub.status.idle":"2025-03-08T12:26:24.059181Z","shell.execute_reply.started":"2025-03-08T12:26:24.049311Z","shell.execute_reply":"2025-03-08T12:26:24.058145Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# train_sample = train_data.select(range(30000))  \n# test_sample = train_data.select(range(30001, 31100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:36:03.450789Z","iopub.execute_input":"2025-03-08T11:36:03.451184Z","iopub.status.idle":"2025-03-08T11:36:03.467677Z","shell.execute_reply.started":"2025-03-08T11:36:03.451155Z","shell.execute_reply":"2025-03-08T11:36:03.466812Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:26:37.045239Z","iopub.execute_input":"2025-03-08T12:26:37.045625Z","iopub.status.idle":"2025-03-08T12:26:37.147245Z","shell.execute_reply.started":"2025-03-08T12:26:37.045593Z","shell.execute_reply":"2025-03-08T12:26:37.146366Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"X_train = [entry['text'] for entry in train_sample]\ny_train = [entry['is_tts'] for entry in train_sample]\nX_test = [entry['text'] for entry in test_sample]\ny_test = [entry['is_tts'] for entry in test_sample]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:26:56.807617Z","iopub.execute_input":"2025-03-08T12:26:56.807926Z","iopub.status.idle":"2025-03-08T12:26:58.164847Z","shell.execute_reply.started":"2025-03-08T12:26:56.807903Z","shell.execute_reply":"2025-03-08T12:26:58.163927Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# model_name = \"bert-base-uncased\"  \n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:15:09.593426Z","iopub.execute_input":"2025-03-08T11:15:09.593997Z","iopub.status.idle":"2025-03-08T11:15:31.268574Z","shell.execute_reply.started":"2025-03-08T11:15:09.593968Z","shell.execute_reply":"2025-03-08T11:15:31.267876Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f9a3f432b384433befdc7cefb5ebc04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea0f62bd7449483aac2fde5e73e57a1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae276a9c6a64bb8ad60e90f4ecc9735"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a27a84aea76d45c3935435bf7da109cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dcd944a497b465492555c6f1ef6db7c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\n\nmodel_name = \"/kaggle/input/wav2vec2/tensorflow2/xlsr-53/1\"  # Local path to the model\nmodel = tf.saved_model.load(model_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:34:28.054599Z","iopub.execute_input":"2025-03-08T12:34:28.054926Z","iopub.status.idle":"2025-03-08T12:34:52.467349Z","shell.execute_reply.started":"2025-03-08T12:34:28.054897Z","shell.execute_reply":"2025-03-08T12:34:52.466624Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"import librosa\nimport tensorflow as tf\nimport numpy as np\n\n# Update the preprocess function to decode and convert the audio to the required format\ndef preprocess_audio(audio_data, sampling_rate=16000, target_length=246000):\n    # Assuming audio_data is a byte string that needs to be decoded\n    # Decode the audio (if it's in a byte string format like wav or mp3)\n    audio_array, _ = librosa.load(audio_data, sr=sampling_rate)\n    \n    # Ensure the audio is the correct length (pad or truncate)\n    if len(audio_array) > target_length:\n        audio_array = audio_array[:target_length]\n    else:\n        audio_array = np.pad(audio_array, (0, target_length - len(audio_array)), mode='constant')\n\n    # Reshape the audio to be (1, target_length) and convert to float32\n    audio_array = np.expand_dims(audio_array, axis=0).astype(np.float32)\n\n    # Now we assume stereo input, so we duplicate the audio for input_1 and input_2\n    audio_data_dual = np.stack([audio_array, audio_array], axis=1)  # shape: (1, 2, target_length)\n    \n    return audio_data_dual","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:45:31.633779Z","iopub.execute_input":"2025-03-08T12:45:31.634175Z","iopub.status.idle":"2025-03-08T12:45:31.639474Z","shell.execute_reply.started":"2025-03-08T12:45:31.634146Z","shell.execute_reply":"2025-03-08T12:45:31.638587Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"train_inputs = [preprocess_audio(audio) for audio in X_train]\ntest_inputs = [preprocess_audio(audio) for audio in X_test]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:40:44.047276Z","iopub.execute_input":"2025-03-08T12:40:44.047558Z","iopub.status.idle":"2025-03-08T12:40:44.051912Z","shell.execute_reply.started":"2025-03-08T12:40:44.047537Z","shell.execute_reply":"2025-03-08T12:40:44.051192Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"def predict(model, audio_input):\n    infer = model.signatures[\"serving_default\"]  # Use the default signature to get predictions\n    # Pass the same input to both input_1 and input_2\n    predictions = infer(input_1=tf.convert_to_tensor(audio_input), input_2=tf.convert_to_tensor(audio_input))  \n    logits = predictions[\"output_1\"].numpy()  # Get the logits (raw output)\n    return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:45:41.807995Z","iopub.execute_input":"2025-03-08T12:45:41.808308Z","iopub.status.idle":"2025-03-08T12:45:41.812659Z","shell.execute_reply.started":"2025-03-08T12:45:41.808282Z","shell.execute_reply":"2025-03-08T12:45:41.811815Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"y_pred = []\nfor audio_data in test_inputs:\n    logits = predict(model, audio_data)\n    \n    # For binary classification, logits are a single value per sample\n    # Apply sigmoid to get the probability of the positive class (class 1)\n    probs = tf.sigmoid(logits).numpy()\n    \n    # If the model outputs one logit, this will be a single value (probability of class 1)\n    y_pred.extend(probs.flatten()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:45:49.438910Z","iopub.execute_input":"2025-03-08T12:45:49.439222Z","iopub.status.idle":"2025-03-08T12:45:49.487350Z","shell.execute_reply.started":"2025-03-08T12:45:49.439198Z","shell.execute_reply":"2025-03-08T12:45:49.486027Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     bound_arguments = function_type.bind_with_defaults(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitized_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36mbind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         with_default_args[arg_name] = constraint.cast(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mwith_default_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(self, value, casting_context)\u001b[0m\n\u001b[1;32m   1114\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can not cast {value_spec!r} to {self!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Can not cast TensorSpec(shape=(1,), dtype=tf.string, name='input_1') to TensorSpec(shape=(None, 246000), dtype=tf.float32, name='input_1')","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     bound_args = (\n\u001b[0;32m-> 1259\u001b[0;31m         function_type_utils.canonicalize_function_inputs(\n\u001b[0m\u001b[1;32m   1260\u001b[0m             args, kwargs, self.function_type)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m   bound_arguments = bind_function_inputs(\n\u001b[0m\u001b[1;32m    423\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py\u001b[0m in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;34mf\"Binding inputs to tf.function failed due to `{e}`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(1,), dtype=tf.string, name='input_1') to TensorSpec(shape=(None, 246000), dtype=tf.float32, name='input_1')`. Received args: () and kwargs: {'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=\narray([b\"\\xe0\\xa6\\x85\\xe0\\xa6\\xa8\\xe0\\xa7\\x81\\xe0\\xa6\\x97\\xe0\\xa7\\x8d\\xe0\\xa6\\xb0\\xe0\\xa6\\xb9 \\xe0\\xa6\\x95\\xe0\\xa7\\xb0\\xe0\\xa6\\xbf \\xe0\\xa6\\x9f\\xe0\\xa7\\x81\\xe0\\xa7\\xb1\\xe0\\xa7\\x87\\xe0\\xa6\\xa3\\xe0\\xa7\\x8d\\xe0\\xa6\\x9f\\xe0\\xa6\\xbf \\xe0\\xa6\\xab'\\xe0\\xa7\\xb0 \\xe0\\xa6\\xae\\xe0\\xa6\\xa8\\xe0\\xa7\\x8d\\xe0\\xa6\\xa4\\xe0\\xa7\\x8d\\xe0\\xa6\\xb0\\xe0\\xa6\\xbe \\xe0\\xa6\\xb8\\xe0\\xa6\\xa4\\xe0\\xa7\\x8d\\xe0\\xa6\\xa4\\xe0\\xa7\\x81 \\xe0\\xa6\\x86\\xe0\\xa6\\x9f\\xe0\\xa6\\xbe \\xe0\\xa6\\x86\\xe0\\xa7\\xb0\\xe0\\xa7\\x81 \\xe0\\xa6\\x9c\\xe0\\xa7\\x87\\xe0\\xa6\\x9b\\xe0\\xa6\\xa8\\xe0\\xa7\\x8d\\xe2\\x80\\x8c\\xe0\\xa6\\x9b \\xe0\\xa6\\xab\\xe0\\xa7\\x8d\\xe0\\xa6\\xb2'\\xe0\\xa7\\xb0\\xe0\\xa6\\xbe \\xe0\\xa6\\xae\\xe0\\xa6\\xbe\\xe0\\xa6\\x87\\xe0\\xa6\\x95\\xe0\\xa7\\x8d\\xe0\\xa7\\xb0\\xe0\\xa7\\xb1\\xe0\\xa7\\x87'\\xe0\\xa6\\xad \\xe0\\xa6\\xac'\\xe0\\xa6\\xb2 \\xe0\\xa6\\x9b\\xe0\\xa7\\x87\\xe0\\xa6\\x9f \\xe0\\xa6\\x86\\xe0\\xa6\\x9c\\xe0\\xa6\\xbf\\xe0\\xa7\\xb0 \\xe0\\xa6\\xad\\xe0\\xa6\\xbf\\xe0\\xa6\\xa4\\xe0\\xa7\\xb0\\xe0\\xa6\\xa4\\xe0\\xa7\\x87 \\xe0\\xa6\\xa1\\xe0\\xa7\\x87\\xe0\\xa6\\xb2\\xe0\\xa6\\xbf\\xe0\\xa6\\xad\\xe0\\xa6\\xbe\\xe0\\xa7\\xb0 \\xe0\\xa6\\x95\\xe0\\xa7\\xb0\\xe0\\xa6\\xbf \\xe0\\xa6\\xa6\\xe0\\xa6\\xbf\\xe0\\xa6\\xac\\xe0\\xa6\\xbe\\xe0\\xa5\\xa4\"],\n      dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=\narray([b\"\\xe0\\xa6\\x85\\xe0\\xa6\\xa8\\xe0\\xa7\\x81\\xe0\\xa6\\x97\\xe0\\xa7\\x8d\\xe0\\xa6\\xb0\\xe0\\xa6\\xb9 \\xe0\\xa6\\x95\\xe0\\xa7\\xb0\\xe0\\xa6\\xbf \\xe0\\xa6\\x9f\\xe0\\xa7\\x81\\xe0\\xa7\\xb1\\xe0\\xa7\\x87\\xe0\\xa6\\xa3\\xe0\\xa7\\x8d\\xe0\\xa6\\x9f\\xe0\\xa6\\xbf \\xe0\\xa6\\xab'\\xe0\\xa7\\xb0 \\xe0\\xa6\\xae\\xe0\\xa6\\xa8\\xe0\\xa7\\x8d\\xe0\\xa6\\xa4\\xe0\\xa7\\x8d\\xe0\\xa6\\xb0\\xe0\\xa6\\xbe \\xe0\\xa6\\xb8\\xe0\\xa6\\xa4\\xe0\\xa7\\x8d\\xe0\\xa6\\xa4\\xe0\\xa7\\x81 \\xe0\\xa6\\x86\\xe0\\xa6\\x9f\\xe0\\xa6\\xbe \\xe0\\xa6\\x86\\xe0\\xa7\\xb0\\xe0\\xa7\\x81 \\xe0\\xa6\\x9c\\xe0\\xa7\\x87\\xe0\\xa6\\x9b\\xe0\\xa6\\xa8\\xe0\\xa7\\x8d\\xe2\\x80\\x8c\\xe0\\xa6\\x9b \\xe0\\xa6\\xab\\xe0\\xa7\\x8d\\xe0\\xa6\\xb2'\\xe0\\xa7\\xb0\\xe0\\xa6\\xbe \\xe0\\xa6\\xae\\xe0\\xa6\\xbe\\xe0\\xa6\\x87\\xe0\\xa6\\x95\\xe0\\xa7\\x8d\\xe0\\xa7\\xb0\\xe0\\xa7\\xb1\\xe0\\xa7\\x87'\\xe0\\xa6\\xad \\xe0\\xa6\\xac'\\xe0\\xa6\\xb2 \\xe0\\xa6\\x9b\\xe0\\xa7\\x87\\xe0\\xa6\\x9f \\xe0\\xa6\\x86\\xe0\\xa6\\x9c\\xe0\\xa6\\xbf\\xe0\\xa7\\xb0 \\xe0\\xa6\\xad\\xe0\\xa6\\xbf\\xe0\\xa6\\xa4\\xe0\\xa7\\xb0\\xe0\\xa6\\xa4\\xe0\\xa7\\x87 \\xe0\\xa6\\xa1\\xe0\\xa7\\x87\\xe0\\xa6\\xb2\\xe0\\xa6\\xbf\\xe0\\xa6\\xad\\xe0\\xa6\\xbe\\xe0\\xa7\\xb0 \\xe0\\xa6\\x95\\xe0\\xa7\\xb0\\xe0\\xa6\\xbf \\xe0\\xa6\\xa6\\xe0\\xa6\\xbf\\xe0\\xa6\\xac\\xe0\\xa6\\xbe\\xe0\\xa5\\xa4\"],\n      dtype=object)>} for signature: (*, input_1: TensorSpec(shape=(None, 246000), dtype=tf.float32, name='input_1'), input_2: TensorSpec(shape=(None, 246000), dtype=tf.float32, name='input_2')) -> Dict[['output_1', TensorSpec(shape=(None, 768, 1024), dtype=tf.float32, name='output_1')]].","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-05e5c291e79a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maudio_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# For binary classification, logits are a single value per sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-77-efe4871e6aa8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, audio_input)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"serving_default\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Use the default signature to get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Pass the same input to both input_1 and input_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the logits (raw output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \"\"\"\n\u001b[0;32m-> 1170\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mflat_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             raise TypeError(  # pylint: disable=raise-missing-from\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                         \u001b[0;34mf\"#{i}(zero-based) to be a Tensor; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m                         f\"got {type(arg).__name__} ({arg}).\")\n\u001b[0;32m-> 1242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# cross-replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unused_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute __inference_signature_wrapper_25727 as input #0(zero-based) was expected to be a float tensor but is a string tensor [Op:__inference_signature_wrapper_25727]"],"ename":"InvalidArgumentError","evalue":"cannot compute __inference_signature_wrapper_25727 as input #0(zero-based) was expected to be a float tensor but is a string tensor [Op:__inference_signature_wrapper_25727]","output_type":"error"}],"execution_count":78},{"cell_type":"code","source":"# train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n# test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:44:33.983765Z","iopub.execute_input":"2025-03-08T11:44:33.984124Z","iopub.status.idle":"2025-03-08T11:44:36.937342Z","shell.execute_reply.started":"2025-03-08T11:44:33.984094Z","shell.execute_reply":"2025-03-08T11:44:36.936615Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# train_dataset = torch.utils.data.TensorDataset(\n#     torch.tensor(train_encodings['input_ids']),\n#     torch.tensor(train_encodings['attention_mask']),\n#     torch.tensor(y_train)\n# )\n\n# test_dataset = torch.utils.data.TensorDataset(\n#     torch.tensor(test_encodings['input_ids']),\n#     torch.tensor(test_encodings['attention_mask']),\n#     torch.tensor(y_test)\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:44:39.326277Z","iopub.execute_input":"2025-03-08T11:44:39.326589Z","iopub.status.idle":"2025-03-08T11:44:40.673169Z","shell.execute_reply.started":"2025-03-08T11:44:39.326560Z","shell.execute_reply":"2025-03-08T11:44:40.672359Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:44:45.051333Z","iopub.execute_input":"2025-03-08T11:44:45.051609Z","iopub.status.idle":"2025-03-08T11:44:45.055956Z","shell.execute_reply.started":"2025-03-08T11:44:45.051586Z","shell.execute_reply":"2025-03-08T11:44:45.055251Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:15:51.647743Z","iopub.execute_input":"2025-03-08T11:15:51.648089Z","iopub.status.idle":"2025-03-08T11:15:52.178507Z","shell.execute_reply.started":"2025-03-08T11:15:51.648060Z","shell.execute_reply":"2025-03-08T11:15:52.177693Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# model.train()\n# for epoch in range(3):  # Run for a few epochs (3 in this case)\n#     for batch in train_loader:\n#         input_ids = batch[0].to(device)\n#         attention_mask = batch[1].to(device)\n#         labels = batch[2].to(device)\n        \n#         model.zero_grad()\n#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n#         loss = outputs.loss\n#         loss.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:44:49.137329Z","iopub.execute_input":"2025-03-08T11:44:49.137617Z","iopub.status.idle":"2025-03-08T12:20:38.405004Z","shell.execute_reply.started":"2025-03-08T11:44:49.137593Z","shell.execute_reply":"2025-03-08T12:20:38.404222Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# model.eval()\n# y_pred = []\n# with torch.no_grad():\n#     for batch in test_loader:\n#         input_ids = batch[0].to(device)\n#         attention_mask = batch[1].to(device)\n        \n#         outputs = model(input_ids, attention_mask=attention_mask)\n#         logits = outputs.logits\n#         probs = torch.nn.functional.softmax(logits, dim=1)  \n#         y_pred.extend(probs[:, 1].cpu().numpy()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:20:44.869512Z","iopub.execute_input":"2025-03-08T12:20:44.869771Z","iopub.status.idle":"2025-03-08T12:20:50.981982Z","shell.execute_reply.started":"2025-03-08T12:20:44.869744Z","shell.execute_reply":"2025-03-08T12:20:50.981245Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# roc_auc = roc_auc_score(y_test, y_pred)\n# print(f\"ROC AUC Score: {roc_auc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T12:21:08.818649Z","iopub.execute_input":"2025-03-08T12:21:08.819012Z","iopub.status.idle":"2025-03-08T12:21:08.826990Z","shell.execute_reply.started":"2025-03-08T12:21:08.818980Z","shell.execute_reply":"2025-03-08T12:21:08.826265Z"}},"outputs":[{"name":"stdout","text":"ROC AUC Score: 0.5258983275376717\n","output_type":"stream"}],"execution_count":43}]}